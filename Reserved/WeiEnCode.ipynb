{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35027598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c984ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Names: ['A&E Service Fees', 'Abdominal Binder', 'Abiraterone', 'Acarbose', 'Access Instument', 'Acetazolamide', 'Acetic Acid', 'Acetone', 'Acetylcysteine', 'Aciclovir', 'Adalimumab', 'Adapalene', 'Ademetionine', 'Adenosine', 'Adhesive Remover', 'Admin Fee', 'Admission Processing Fee', 'Adrenaline', 'Afatinib dimaleate', 'Aflibercept', 'Agomelatine', 'Airway', 'Airway Connector', 'Albumin', 'Alcohol Solution alone', 'Alendronic Acid', 'Alfacalcidol', 'Alfentanil', 'Allopurinol', 'Alpha-lipoic acid', 'Alprazolam', 'Alteplase', 'Aluminium HYD+Mg Tri+Simethicon', 'Alverine citrate + Simethicone', 'Ambroxol', 'Ambulance Service', 'Amikacin', 'Amiloride', 'Amiodarone', 'Amitriptyline', 'Amlodipine', 'Amlodipine + Valsartan', 'Amlodipine+Valsartan+HCT', 'Amoxicillin', 'Amoxicillin + Clavulanic Acid', 'Ampicillin', 'Anaesthesia Fees', 'Anastrazole', 'Anchoring Device', 'Anidulafungin', 'Anti-D Immunoglobulins', 'Anti-fog Soln', 'Antithymocyte Immunoglobulin', 'Apixaban', 'Appetite Enhancers', 'Aprepitant', 'Arnica Montana', 'Arsenic Trioxide', 'Aspirin', 'Assistant Fee', 'Atracurium Besilate', 'Atenolol', 'Atezolizumab', 'Atorvastatin', 'Atovaquone', 'Atropine', 'Axitinib', 'Azacitidine', 'Azathioprine', 'Azithromycin', 'Aztreonam', 'Baclofen', 'Bag', 'Balloon', 'Bandage', 'Basiliximab', 'Basin', 'BCG', 'Beclometasone', 'Bedding', 'Bedpan and Urinal', 'Bendamustine', 'Benzathine Benzylpenicillin', 'Benzoyl Peroxide + Clindamycin', 'Benzydamine hydrochloride', 'Betahistine', 'Betameta+Clotrimazole+Genta', 'Betamethasone', 'Betamethasone + Clioquinol', 'Bevacizumab', 'Bicalutamide', 'Biopsy Consumable', 'Bisacodyl', 'Bisoprolol', 'Bite Block', 'Blanket', 'Bleach', 'Bleomycin', 'Blinatumomab', 'Blue Dye', 'Body Protector', 'Bone Cement', 'Bortezomib', 'Bowel Preps', 'Bowls', 'Brain surgery consumables', 'Breathing Circuit', 'Brentuximab', 'Brimonidine tartrate', 'Brinzolamide + Timolol', 'Bromazepam', 'Bromhexine', 'Budesonide', 'Budesonide + Formoterol', 'Bumetanide', 'Bupivacaine', 'Bupivacaine + Adrenaline', 'Buserelin', 'Busulfan', 'CADD consumables', 'Cadexomer Iodine', 'Calamine', 'Calcipotriol + Betamethasone', 'Calcitonin', 'Calcitriol', 'Calcium Acetate', 'Calcium Carbonate', 'Calcium carbonate + Vitamin D3', 'Calcium Chloride', 'Calcium Gluconate', 'Call Back Fee', 'Camphor+Menthol+Methyl salicyla', 'Candesartan', 'Capecitabine', 'Captopril', 'Carbamazepine', 'Carboplatin', 'Carmustine', 'Carvedilol', 'Carbidopa+Levodopa+Entacapone', 'Carbimazole', 'Carbocisteine', 'Carbocisteine+Promethazine', 'Caspofungin', 'Catheter', 'Catheter Clamp', 'Catheter Introducer', 'Cefaclor', 'Cefalexin', 'Cefepime', 'Cefoxitin', 'Ceftaroline', 'Ceftazidime', 'Ceftibuten', 'Ceftolozane + Tazobactam', 'Ceftriaxone', 'Cefuroxime', 'Ceftazidime + Avibactam', 'Celecoxib', 'Cephazolin', 'Cetirizine', 'Cetirizine + Pseudoephedrine', 'Cetuximab', 'Chemo Consumable Fee', 'Chemo Prep Fee', 'Chest Drainage', 'Chloramphenicol', 'Chlordiazepoxide + Clidinium Br', 'Chlorhexidine', 'Chlorphenamine', 'Chlorpromazine', 'Chlortetracycline', 'Cholestyramine', 'Choline Salicylate+Cetalkonium', 'Choriogonadotropin alfa', 'Ciclosporin', 'Cidofovir', 'Cimicifuga rhizome', 'Cinnarizine', 'Ciprofloxacin', 'Cisplatin', 'Clarithromycin', 'Cleansing Set', 'Clindamycin', 'Clobazam', 'Clobetasol Propionate', 'Clofarabine', 'Clonazepam', 'Clonidine', 'Clopidogrel', 'Clopidogrel+AcetylsalicylicAcid', 'Clostridium Botulinum ToxinA', 'Closure Device', 'Clotrimazole', 'Clotrimazole+Beclometa+Genta', 'Clotrimazole + Hydrocortisone', 'Coal Tar', 'Codeine', 'Codeine + Phenyltoloxamine', 'Codeine+Promethazine', 'Codeine+Promethazine+Ephedrine', 'Colchicine', 'Compound Sodium Lactate', 'Colistin', 'Consultation Fees', 'Container Liner', 'Contrast', 'Corifollitropin alfa', 'Covers', 'CT', 'Cyclophosphamide', 'Cytarabine', 'Cytomegalovirus Immunoglobulin', 'Dabigatran etexilate', 'Dabrafenib', 'Dacarbazine', 'Daclatasvir', 'Dactinomycin', 'Daily Treatment Fee', 'Dapagliflozin', 'Dapagliflozin + Metformin', 'Dapsone', 'Daptomycin', 'Daratumumab', 'Darbepoetin Alfa', 'Dasatinib', 'Data Storage Device', 'Daunorubicin', 'Decapeptide Ganirelix', 'Deferasirox', 'Defib Pads', 'Degarelix', 'Denosumab', 'Dental Fee', 'Dequalinium Chloride', 'Desloratadine', 'Desmopressin acetate', 'Desonide', 'Dexamethasone', 'Dexametha+Neomycin+Polymyxin B', 'Dexlansoprazole', 'Dexmedetomidine', 'Dexrazoxane', 'Dextromethorphan', 'Dextrose', 'Dextrose + Sodium Chloride', 'Dialysis Charges', 'Diapers', 'Diazepam', 'Diclofenac', 'Dicyclomine HCl+Simethicone', 'Dietician', 'Digoxin', 'Dilation', 'Diltiazem', 'Dioctahedral smectite', 'Diosmin + Hesperidin', 'Diphenhydramine', 'Diphenoxylate + Atropine', 'Disease MX Fee', 'Distigmine Bromide', 'Docetaxel', 'Doctor Treatment Fees', 'Docusate sodium', 'Domperidone', 'Donepezil', 'Donor Organ Preserving', 'Dopamine', 'Doripenem', 'Doxazosin', 'Doxorubicin', 'Doxycycline', 'Drainage Collection', 'Drainage Tubing', 'Drawsheet', 'Dressing Consumable', 'Dressing Set', 'Dronedarone', 'Droperidol', 'Dulaglutide', 'Duloxetine', 'Dutasteride', 'Dutasteride+Tamsulosin', 'ECG', 'ECG Electrodes', 'Echocardiogram', 'EEG Eelctrode Sensor', 'Efavirenz', 'Electrodes Cleaning Pad', 'Electrolyte mix', 'Electronic Documentation', 'Elemental Calcium + Vitamin D3', 'Eltrombopag', 'Emergency Procedure', 'Empagliflozin', 'Empagliflozin + Linagliptin', 'Emtricitabine + Tenofovir', 'Enalapril', 'Energy OT Instrument', 'Enoxaparin', 'Entecavir', 'Enteral Nutrition', 'Enzalutamide', 'Enzyplex', 'Eperisone', 'Ephedrine', 'Epirubicin', 'Eplerenone', 'Epoetin alfa', 'Epoetin beta', 'Eptacog alfa', 'Ergotamine + Caffeine', 'Eribulin', 'Erlotinib', 'Ertapenem', 'Erythromycin', 'Escitalopram', 'Esmolol', 'Esomeprazole', 'Essential keto acids', 'Estradiol', 'Estradiol Valerate + Norgestrel', 'Estrogen', 'Etamsylate', 'ETCO2 Monitoring', 'ETCO2 Sensor', 'Ethambutol', 'Etomidate', 'Etoposide', 'Etoricoxib', 'ETT', 'EVD', 'Evening Primrose Oil', 'Everolimus', 'Exemestane', 'Eye Guard', 'Eye Examinations', 'Ezetimibe', 'Ezetimibe + Simvastatin', 'Facility Fee', 'Famotidine', 'Febuxostat', 'Feeding Bag', 'Feeding Tube', 'Fenofibrate', 'Fentanyl', 'Ferric carboxymaltose', 'Ferrous Fumarate', 'Ferrous Gluconate', 'Ferrous Sulfate', 'Fexofenadine', 'Fexofenadine + Pseudoephedrine', 'Filgrastim', 'Finasteride', 'Flavoxate', 'Flow Sensor', 'Fluconazole', 'Fludarabine', 'Fludrocortisone', 'Flumazenil', 'Fluorometholone', 'Fluorouracil', 'Fluoxetine', 'Fluroscopy', 'Fluticasone furoate', 'Fluticasone Furoate+Vilanterol', 'Fluticasone propionate', 'Fluticasone PRO+ Formoterol', 'FMS', 'Folinic acid', 'Follitropin alfa', 'Fosfomycin', 'Foscarnet', 'Fulvestrant', 'Furosemide', 'Fusidic acid', 'Fusidic acid + Betamethasone', 'Gabapentin', 'GAG Layer Therapy', 'Ganciclovir', 'Gauze and sponge', 'Gemcitabine', 'General Consumable Set', 'General Instrument', 'Gentamicin', 'Ginkgo Biloba', 'Gliclazide', 'Glimepiride', 'Glipizide', 'Gloves', 'Glucosamine Sulphate', 'Glycerol BP', 'Glyceryl trinitrate', 'Glycine', 'Glycopyrronium Bromide', 'Golimumab', 'Goserelin', 'Gown', 'Granisetron', 'Green Oats + Nettle Extract', 'Guaifenesin', 'Guidewire', 'H2O for Respiratory Use', 'Hair Care', 'Haloperidol', 'Hearing Test', 'Heart Surgery Consumable', 'Hedera Helix', 'Hemodynamic Monitoring', 'Hemostatic', 'Heparin', 'Heparinoids', 'Hepatitis B Vaccine', 'HF Nasal Cannula', 'Histology', 'Human Normal Immunoglobulin', 'Hyaluronidase', 'Hydralazine', 'Hydrocortisone', 'Hydrocortisone + Cinchocaine', 'Hydrogen Peroxide', 'Hydroxycarbamide', 'Hydroxychloroquine', 'Hydrochlorothiazide', 'Hydroxyethyl starch', 'Hydroxyzine', 'Hylan G-F 20', 'Hyoscine-N-butylbromide', 'Ibrutinib', 'Ibuprofen', 'Idarubicin', 'Ifosfamide', 'Imatinib', 'Imipenem + Cilastatin', 'Imipramine', 'Incentive Spirometer', 'Incopad', 'Indapamide', 'Indigo Carmine', 'Indocyanine Green', 'Indometacin', 'Influenza Vaccine', 'Instrument Processing Fee', 'Instrument Set', 'Instument use', 'Insulin Preparation', 'Intrathecal', 'Intubation Stylet', 'Invasive Pressure Monitoring', 'Iodine', 'Ipilimumab', 'Ipratropium bromide', 'Ipratropium BR + Fenoterol', 'Ipratropium BR + Salbutamol', 'Irbesartan', 'Irbesartan+Hydrochlorothiazide', 'Irinotecan', 'Iron Polymaltose', 'Iron sucrose', 'Isavuconazole', 'Isoconazole + Diflucortolone', 'Isolation Fee', 'Isoniazid', 'Isosorbide Dinitrate', 'Isosorbide Mononitrate', 'Ispaghula husk', 'Itraconazole', 'I.V. Adaptor', 'I.V. Cannula', 'I.V. Connector & Extension', 'I.V. Plug', 'I.V. Tubing', 'Ivabradine', 'Ivermectin', 'Jug', 'Kaolin', 'Ketamine', 'Ketoconazole', 'Ketoprofen', 'Ketorolac', 'L-Alanyl-L-Glutamine', 'L-Asparaginase', 'Label', 'Lab - Biochemistry', 'Lab - Cyto', 'Lab - Haematology', 'Lab - Immunology', 'Lab - Microbiology', 'Lab - Molecular Diagnosis', 'Lab - Pathology', 'Lab Service Fees', 'Labetalol', 'Lactobacillus acidophilus', 'Lactulose', 'Lamivudine', 'Lamotrigine', 'Lancet', 'Lanreotide', 'Lansoprazole', 'Lapatinib', 'Laryngoscope', 'Latanoprost ', 'Lenalidomide', 'Lenvatinib', 'Letrozole', 'Leuprorelin', 'Levetiracetam', 'Levobupivacaine', 'Levocetirizine', 'Levodopa + Benserazide', 'Levofloxacin', 'Levothyroxine', 'Lidocaine', 'Lidocaine+Chlorhex+Triamcinolon', 'Lidocaine+Prilocaine', 'Lidocaine+Triamcinolone', 'Ligating Clips', 'Lignocaine + Aminacrine', 'Lignocaine + Phenylephrine', 'Limb Compression Device', 'Linagliptin', 'Linagliptin + Metformin', 'Linezolid', 'Liposomal amphotericin B', 'Liquid Skin Adhesive', 'Liraglutide', 'Lisinopril', 'Lomustine', 'Loperamide', 'Loratadine', 'Loratadine + Pseudoephedrine', 'Lorazepam', 'Losartan', 'Lubricating Jelly', 'Lung Function Test', 'Machine services', 'Machine use', 'Macitentan', 'Magnesium CARB + Na Bicarb', 'Magnesium', 'Main Ultrasound', 'Malathion', 'Mannitol', 'Manual Resuscitator', 'Maraviroc', 'Mask', 'Mattress', 'Mecobalamin', 'Medical Protection Supplies', 'Medical Tray', 'Medium Chain Triglycerides', 'Mefenamic Acid', 'Megestrol', 'Melatonin', 'Melphalan', 'Memantine', 'Meningococcal Vaccine', 'Menotrophin', 'Mercaptopurine', 'Meropenem', 'Mesalazine', 'Mesh', 'Mesna', 'Metformin', 'Menthol + methyl salicylate', 'Methotrexate', 'Methoxy polyethylene glycol-epo', 'Methyldopa', 'Methylphenidate', 'Methylprednisolone', 'Methyl Salicylate', 'Methylene Blue', 'Metoclopramide', 'Metolazone', 'Metoprolol', 'Metronidazole', 'Metronidazole + Nystatin', 'Mebeverine', 'Micafungin', 'Miconazole', 'Miconazole + Hydrocortisone', 'Midazolam', 'Midodrine', 'Milrinone', 'Minocycline', 'Mirabegron', 'Mirtazapine', 'Misc Connectors', 'Misc Container', 'Misc Medical Supplies Set', 'Misoprostol', 'Mitomycin', 'Mixed Bacteria Vaccine', 'Mobile Aid', 'Mometasone furoate', 'Montelukast', 'Morphine', 'Motion Restrictor', 'Moxifloxacin', 'MRI', 'Mucus extractor', 'Multi-Vitamin', 'Mupirocin', 'Mycophenolate mofetil', 'Mycophenolate sodium', 'Na Alginate + K Bicarb', 'Na Alginate+Na Bicarb+Ca Carb', 'Nadroparin calcium', 'Naloxone', 'Nandrolone', 'Naphazoline + Pheniramine', 'Naproxen', 'Nasal Cannula', 'Nebivolol', 'Nebulizer', 'Needle', 'Nelarabine', 'Neomycin', 'Neomycin + Bacitracin', 'Neostigmine', 'Nerve Monitoring Consumables', 'Netupitant + Palonosetron', 'Neurological Examination', 'NIBP Cuff', 'Nicotine', 'Nifedipine', 'Nilotinib', 'Nitrazepam', 'Nitrofurantoin', 'Nivolumab', 'Non-surgical Procedure', 'Noradrenaline Bitartrate', 'Nordazepam', 'Norepinephrine', 'Norethisterone', 'Nortriptyline', 'Nozzle or Tip', 'NPWT', 'Nuclear Medicine', 'Nursing Charge', 'Nutritional Feeds', 'Nystatin', 'O2 Tubing', 'Obinutuzumab', 'Occupational Therapy', 'Octenidine', 'Octreotide', 'Ofloxacin', 'Olanzapine', 'Olaparib', 'Olopatadine', 'Omega 3', 'Ondansetron', 'Ophthalmic lubricants', 'Oral Contraceptives', 'Oral Health', 'Oral Suspending Vehicle', 'Oseltamivir', 'Osimertinib', 'OT Anaesthesia Time', 'OT Instrument', 'OT Machine', 'OT Procedure Set', 'OT Recovery Time', 'OT Use', 'OT Xray Use', 'Other Cardiac Examination', 'Other Urology Examinations', 'Oxaliplatin', 'Oxcarbazepine', 'Oxycodone', 'Oxycodone + Naloxone', 'Oxygen Use', 'Oxymetazoline', 'Oxytetracycline + Polymyxin B', 'Paclitaxel', 'Pain Relief System', 'Pain Services', 'Palbociclib', 'Palonosetron', 'Pancreatin', 'Panitumumab', 'Pantoprazole', 'Papaverine', 'Paracetamol', 'Paracetamol + Codeine', 'Paracetamol + Orphenadrine', 'Paracetamol + Tramadol', 'Pathologist', 'Patient Garments', 'Patient Monitoring', 'Parecoxib', 'Parenteral Nutrition', 'Pazopanib', 'Peep Valve', 'Pegaspargase', 'Pegfilgrastim', 'Pelargonium sidoides root extr', 'Pembrolizumab', 'Pemetrexed', 'Pentamidine', 'Pentoxifylline', 'Peppermint Oil', 'Perfusion Accessories', 'Perindopril', 'Perindopril+Amlodipine', 'Perindopril+Bisoprolol', 'Pertuzumab', 'Pethidine', 'Pharmaceutical Fee', 'Pharmaceutical Haemostatics', 'Phenazopyridine', 'Phenylephrine', 'Phenytoin', 'Phetermine', 'Pholcodine', 'Phospholipids', 'Physical Recovery Aid', 'Physiotherapy', 'Pillow', 'Pimecrolimus', 'Pioglitazone', 'Piperacillin + Tazobactam', 'Piracetam', 'Plasma Protein Fraction', 'Plerixafor', 'Pneumococcal Vaccine', 'POCT Blood test', 'POCT Urine test', 'Podiatry', 'Polymyxin B', 'Polyphenol supplement', 'Polypodiumleucotomos', 'Pomalidomide', 'Posaconazole', 'Potassium Acetate', 'Potassium Chloride', 'Potassium Dihydrogen Phosphate', 'Potassium Iodine', 'Potassium Permanganate', 'Potassium Phosphate', 'Povidone Iodine', 'Pramipexole', 'Prazosin', 'Prednisolone', 'Pregabalin', 'Pressure Infusor Bag', 'Primaquine', 'Printing', 'Private Doctor Procedure Fees', 'Probiotic', 'Probiotic + Prebiotic', 'Procarbazine', 'Prochlorperazine', 'Proflavine', 'Promethazine', 'Propolis extr', 'Propofol', 'Propranolol', 'Prosthesis and Implant', 'Protamine Sulfate', 'Prucalopride', 'Pt. Warming Devices', 'Public Hosp. Procedure Fee', 'Pumps', 'Purified sea water', 'Quetiapine', 'Rabeprazole', 'Racecadotril', 'Radiofrequency consumable', 'Radiofrequency Machine Usage', 'Radiotherapy', 'Raltegravir', 'Ramipril', 'Ramucirumab', 'Ranitidine', 'Rapid Diagnostic Test Kit', 'Rasburicase', 'Regorafenib', 'Rehabilitation Care', 'Remifentanil', 'Repaglinide', 'Reporting', 'Resistant Maltodextrin', 'Respiratory Filter', 'Respiratory Mask', 'Respiratory Machine', 'Respiratory Therapy ', 'Ribavirin', 'Ribociclib', 'Rifampicin', 'Rifaximin', 'Risperidone', 'Ritonavir', 'Rituximab', 'Rivaroxaban', 'Rocuronium bromide', 'Romidepsin', 'Room charges', 'Ropinirole', 'Ropivacaine', 'Rosuvastatin', 'Rotavirus Vaccine', 'Ruxolitinib', 'Sacubitril + Valsartan', 'Salbutamol', 'Salicylic Acid', 'Salmeterol + Fluticasone', 'Sanitary Pads', 'Saxagliptin', 'Scopes and Accessories', 'Scrub Brush', 'Selegiline', 'Selenium', 'Sennosides', 'Sensory Aid', 'Serratiopeptidase', 'Sertraline', 'Service Fee', 'Set Up Charge', 'Sevelamer', 'Sevoflurane', 'Sharps Management', 'Shave', 'Shroud', 'Sildenafil', 'Silver Nitrate', 'Silver Sulfadiazine', \"Silymarin +  Vitamin B's\", 'Simethicone', 'Simvastatin', 'Sinus Wash', 'Sirolimus', 'Sitagliptin', 'Sitagliptin + Metformin', 'Skin Care', 'Skin Marker', 'Snares & Retrieval Pouch', 'Sodium Acetate', 'Sodium Bicarbonate', 'Sodium Chloride', 'Sodium Nitroprusside', 'Sodium Phosphate', 'Sodium Polystyrene Sulfonate', 'Sodium Thiosulfate', 'Sofosbuvir', 'Sofosbuvir + Ledipasvir', 'Sofosbuvir + Velpatasvir', 'Solifenacin', 'Somatostatin', 'Somatropin', 'Sorafenib', 'Sotalol', 'Spacer', 'Specimen Container', 'Speech Therapy', 'Spigot', 'Spironolactone', 'Splint', 'SpO2 sensors', 'Stapler', 'Stapler remover', 'Stent', 'Sterilizing Liquid', 'Stoma bag', 'Stoma base', 'Stoma belt', 'Stoma care product', 'Stoma closure product', 'Stoma set', 'Succinylated Gelatin', 'Sucralfate', 'Suction container', 'Suction filter', 'Suction package', 'Suction Tip Connector', 'Suction Tube', 'Sugammadex', 'Sulfamethoxazole + Trimethoprim', 'Sultamicillin', 'Sunitinib', 'Surgical Blade', 'Surgical Solution', 'Suture', 'Suture Boots', 'Suture Counter', 'Suxamethonium', 'Swab', 'Syringe', 'Tacrolimus', 'Tadalafil', 'Tafluprost', 'Tamoxifen', 'Tamsulosin', 'Tedizolid', 'Tegafur+Gimeracil+Oteracil', 'Telbivudine', 'Telemetry Charge', 'Telmisartan', 'Temozolomide', 'Temperature Pack', 'Temperature Probe', 'Tenofovir alafenamide', 'Tenofovir disoproxil fumarate', 'Terazosin', 'Terbinafine', 'Terlipressin', 'Testosterone', 'Tetracaine', 'Tetracosactide ', 'Tetracycline', 'Thalidomide', 'Theophylline', 'Thiamazole', 'Thioguanine', 'Thiotepa', 'Thymol', 'Thyrotropin alfa', 'Ticagrelor', 'Ticarcillin + Clavulanic Acid', 'Tigecycline', 'Timolol', 'Tinzaparin', 'Tiotropium Bromide', 'Tissue Paper', 'Tobramycin + Dexamethasone', 'Toileting Hygiene', 'Topiramate', 'Topotecan', 'Tornique', 'Tracheostomy Tube', 'Tramadol', 'Trametinib', 'Tranexamic acid', 'Transfusion Services', 'Transplant Fee', 'Trastuzumab', 'Trastuzumab Emtansine', 'Travoprost', 'Triamcinolone Acetonide', 'Trifluridine + Tipiracil', 'Trihexyphenidyl', 'Trimebutine', 'Trimetazidine', 'Triptorelin', 'Trisodium citrate', 'Tubings', 'Ubidecarenone', 'Umeclidinium + Vilantero', 'Unspecified Soln (Gel)', 'Unspecified Soln (Infusion)', 'Unspecified Soln (Irrigation)', 'Unspecified Soln (Spray)', 'Urinary Alkaliniser', 'Urine Bag', 'Urokinase', 'Urosheath', 'Ursodeoxycholic acid', 'Use of Other Gases', 'Valaciclovir', 'Valganciclovir', 'Valproic Acid', 'Valsartan', 'Vancomycin', 'Valsartan + Hydrochlorothiazide', 'Varicella-zoster Vaccine', 'Vascular Intervention', 'Vasopressin', 'Venetoclax', 'Venlafaxine', 'Verapamil', 'Vildagliptin', 'Vildagliptin + Metformin', 'Vinblastine', 'Vincristine', 'Vinorelbine', 'Vitamin + Mineral', 'Vitamin B-complex', 'Vitamin B1', 'Vitamin B6', 'Vitamin B9', 'Vitamin B12', 'Vitamin C', 'Vitamin C + Zinc', 'Vitamin D', 'Vitamin K', 'Voriconazole', 'Warfarin', 'Water', 'Winter Cherry+Indian Frank. etc', 'Wipes', 'Wires and Drills', 'XRay', 'Zinc', 'Zoledronic acid', 'Zolpidem', 'Zopiclone']\n"
     ]
    }
   ],
   "source": [
    "excel_file_path = 'fyp_test.xlsx'\n",
    "\n",
    "xls = pd.ExcelFile(excel_file_path)\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "print(\"Sheet Names:\", sheet_names)\n",
    "\n",
    "excel_sheets = pd.read_excel(excel_file_path, sheet_name=None, header=None)\n",
    "\n",
    "column_info = []\n",
    "for sheet_name, df in excel_sheets.items():\n",
    "    columns = df.iloc[0].tolist()\n",
    "    \n",
    "    for i in columns:\n",
    "        if i not in column_info:\n",
    "            column_info.append(i)\n",
    "column_info.append(\"categories\")\n",
    "maindf =  pd.DataFrame(columns=column_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ac6bec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rename_volume_columns(df):\n",
    "    volume_count = 1\n",
    "    new_columns = []\n",
    "    for column in df.columns:\n",
    "        if 'volume' in column:\n",
    "            new_column_name = f'bolume_{volume_count}'\n",
    "            volume_count += 1\n",
    "        else:\n",
    "            new_column_name = column\n",
    "        new_columns.append(new_column_name)\n",
    "    df.columns = new_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b15919d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_sheets = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for sheet_name, sheet_df in all_sheets.items():\n",
    "    sheet_df['Sheet_Name'] = sheet_name\n",
    "    rename_volume_columns(sheet_df)\n",
    "    try:\n",
    "        combined_df = pd.concat([combined_df, sheet_df], ignore_index=True)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing sheet '{sheet_name}': {e}\")\n",
    "\n",
    "combined_df = combined_df[combined_df.columns.drop(list(combined_df.filter(regex='Unnamed')))]\n",
    "combined_df = combined_df[combined_df.columns.drop(list(combined_df.filter(regex='Volume')))]\n",
    "combined_df.columns = combined_df.columns.str.replace('bolume', 'Volume')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1b97b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/3724801287.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['Year'] = combined_df['PricingDate'].dt.year\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/3724801287.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['tempmonth'] = combined_df['PricingDate'].dt.month\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/3724801287.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['tempday'] = combined_df['PricingDate'].dt.day\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/3724801287.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['Month'] = np.where((combined_df['tempmonth'] == 1) & (combined_df['tempday'] == 1), 1, np.maximum(combined_df['tempmonth'], combined_df['tempday']))\n"
     ]
    }
   ],
   "source": [
    "combined_df['PricingDate'] = pd.to_datetime(combined_df['PricingDate'])\n",
    "\n",
    "combined_df['Year'] = combined_df['PricingDate'].dt.year\n",
    "combined_df['tempmonth'] = combined_df['PricingDate'].dt.month\n",
    "combined_df['tempday'] = combined_df['PricingDate'].dt.day\n",
    "\n",
    "combined_df['Month'] = np.where((combined_df['tempmonth'] == 1) & (combined_df['tempday'] == 1), 1, np.maximum(combined_df['tempmonth'], combined_df['tempday']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61f4d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinecol(df,x,y):\n",
    "    df[x] = df[x].fillna('') + df[y].fillna('')\n",
    "\n",
    "def catcoding(df,x):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"cat_\" + x] = label_encoder.fit_transform(df[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2cfa458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/965655139.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['ApplicationMethod'] = combined_df.loc[:, 'Delivery']\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/965655139.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['OperationArea'] = combined_df.loc[:, 'For Body Part']\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/965655139.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['Surgical Procedure'] = np.where(combined_df['Surgery Name/Procedure Name'].replace('',np.nan).notna(),combined_df['Surgery Name/Procedure Name'],combined_df['Procedure Name'])\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/965655139.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['SpecificConsultant?'] = np.where(combined_df['Consultant'].isnull(), 'No', 'Yes')\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/965655139.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['Urgency?'] = np.where(combined_df['Urgency'].isnull(), 'No', 'Yes')\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/965655139.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['Care Classification'] = combined_df.apply(in_out_care, axis = 1)\n"
     ]
    }
   ],
   "source": [
    "combined_df['Procedure Name'] = combined_df[['Procedure Name', 'Surgery Name/Procedure Name']].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "\n",
    "#ApplicationMethod variable - merge multiple original variables together\n",
    "merge_list = ['Delivery', 'Delivery Medium', 'Route', 'ROUTE', 'USAGE TYPE']\n",
    "\n",
    "combined_df['ApplicationMethod'] = combined_df.loc[:, 'Delivery']\n",
    "combined_df.head()\n",
    "\n",
    "for col in merge_list:\n",
    "    selected_col = combined_df[col]\n",
    "    combined_df['ApplicationMethod'] = np.where(selected_col.replace('',np.nan).notna(),selected_col, combined_df['ApplicationMethod'])\n",
    "merge_list1 = ['Body Part', 'Location']\n",
    "\n",
    "combined_df['OperationArea'] = combined_df.loc[:, 'For Body Part']\n",
    "combined_df.head()\n",
    "\n",
    "for col in merge_list1:\n",
    "    selected_col = combined_df[col]\n",
    "    combined_df['OperationArea'] = np.where(selected_col.replace('',np.nan).notna(),selected_col, combined_df['OperationArea'])\n",
    "\n",
    "#rename variables with more representative names\n",
    "combined_df.rename(columns= {'Volume_1' : 'Vol_1st_med', 'Volume_2': 'Vol_2nd_med', 'Volume_3': 'Vol_3rd_med'} , inplace= 'True')\n",
    "\n",
    "#merge variables together\n",
    "# Disposible? and Disposible variables\n",
    "combined_df['Disposable?'] = np.where(combined_df['Disposable'].replace('',np.nan).notna(),combined_df['Disposable'],combined_df['Disposable?'])\n",
    "combined_df['Disposable?'] = np.where(combined_df['Diposable?'].replace('',np.nan).notna(),combined_df['Diposable?'],combined_df['Disposable?'])\n",
    "\n",
    "#Surgery & prodecure name\n",
    "combined_df['Surgical Procedure'] = np.where(combined_df['Surgery Name/Procedure Name'].replace('',np.nan).notna(),combined_df['Surgery Name/Procedure Name'],combined_df['Procedure Name'])\n",
    "\n",
    "#convert variables into binary variables\n",
    "combined_df['SpecificConsultant?'] = np.where(combined_df['Consultant'].isnull(), 'No', 'Yes')\n",
    "combined_df['Disposable?'] = np.where(combined_df['Disposable?'].isnull(), 'No', 'Yes')\n",
    "combined_df['Urgency?'] = np.where(combined_df['Urgency'].isnull(), 'No', 'Yes')\n",
    "combined_df['Brand'] = np.where(combined_df['Brand '].replace('',np.nan).notna(),combined_df['Brand '],combined_df['Brand'])\n",
    "\n",
    "#convert to cateogorical variables\n",
    "combined_df['Sterile?'] = np.where(combined_df['Sterile?'].isnull(), 'NA', combined_df['Sterile?'])\n",
    "\n",
    "#create new variable - care classification for binary - inpatient and outpatient\n",
    "def in_out_care(df):\n",
    "    \n",
    "    if (df['Ward'] == 'Outpatient'):\n",
    "        return 'Outpatient'\n",
    "    elif (df['Ward'] == 'A&E'): #classification adapted from MOM \n",
    "        return 'Outpatient'\n",
    "    else:\n",
    "        return 'Inpatient'\n",
    "    \n",
    "combined_df['Care Classification'] = combined_df.apply(in_out_care, axis = 1)\n",
    "\n",
    "combined_df.columns = combined_df.columns.str.replace(' ', '_')\n",
    "#removecol = ['Consultant','Condition','QuantityNotMoreThan','Period','Product_Code',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91b3453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['Year'] > 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab453e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_data = combined_df.groupby(['Parent', 'Child'])\n",
    "\n",
    "#groupeddata = grouped_data.filter(lambda x: len(x) >= 3)\n",
    "\n",
    "#filtered_data = grouped_data.filter(lambda x: len(x['Year'].unique()) >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d4c38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_consecutive_years(years):\n",
    "    years_set = set(years)\n",
    "    for year in years_set:\n",
    "        if year + 1 in years_set and year + 2 in years_set:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Group by child and check for consecutive years, then filter\n",
    "filtered_df = combined_df.groupby(['Parent', 'Child']).filter(lambda x: has_consecutive_years(x['Year']) )\n",
    "\n",
    "filtered_df = filtered_df.groupby(['Parent', 'Child']).filter(lambda x: len(x['Year'].unique()) >= 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4697f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbe81dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Hospital</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Consultant</th>\n",
       "      <th>PricingDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>...</th>\n",
       "      <th>Test</th>\n",
       "      <th>Year</th>\n",
       "      <th>tempmonth</th>\n",
       "      <th>tempday</th>\n",
       "      <th>Month</th>\n",
       "      <th>ApplicationMethod</th>\n",
       "      <th>Surgical_Procedure</th>\n",
       "      <th>SpecificConsultant?</th>\n",
       "      <th>Urgency?</th>\n",
       "      <th>Care_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>A&amp;E Amount Transferred</td>\n",
       "      <td>AMOUNT TRANSFERRED</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>A&amp;E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>A&amp;E Amount Transferred</td>\n",
       "      <td>AMOUNT TRANSFERRED</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>A&amp;E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>A&amp;E Amount Transferred</td>\n",
       "      <td>AMOUNT TRANSFERRED</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>A&amp;E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>A&amp;E Amount Transferred</td>\n",
       "      <td>AMOUNT TRANSFERRED</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>A&amp;E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>A&amp;E Amount Transferred</td>\n",
       "      <td>AMOUNT TRANSFERRED</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>A&amp;E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46377</th>\n",
       "      <td>IMOV1</td>\n",
       "      <td>IMOVANE 7.5MG TABLETS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mount Elizabeth Orchard</td>\n",
       "      <td>Outpatient</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>2.12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46379</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>Zopiclone 7.5mg Tablet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>HD Class A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>0.54</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Inpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46380</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>Zopiclone 7.5mg Tablet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>Class A1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-12</td>\n",
       "      <td>0.54</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Inpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46381</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>ZOPICLONE 7.5MG TABLET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National University Hospital</td>\n",
       "      <td>Outpatient</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-12</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46382</th>\n",
       "      <td>n.a.</td>\n",
       "      <td>ZOPICLONE ORAL 7.5MG/TAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Harley Street Heart and Cancer Centre (Nov...</td>\n",
       "      <td>Outpatient</td>\n",
       "      <td>Lo Soo Kien, Sue</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Outpatient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43818 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Code               Description                Type  \\\n",
       "0       n.a.    A&E Amount Transferred  AMOUNT TRANSFERRED   \n",
       "1       n.a.    A&E Amount Transferred  AMOUNT TRANSFERRED   \n",
       "2       n.a.    A&E Amount Transferred  AMOUNT TRANSFERRED   \n",
       "3       n.a.    A&E Amount Transferred  AMOUNT TRANSFERRED   \n",
       "4       n.a.    A&E Amount Transferred  AMOUNT TRANSFERRED   \n",
       "...      ...                       ...                 ...   \n",
       "46377  IMOV1     IMOVANE 7.5MG TABLETS                 NaN   \n",
       "46379   n.a.    Zopiclone 7.5mg Tablet                 NaN   \n",
       "46380   n.a.    Zopiclone 7.5mg Tablet                 NaN   \n",
       "46381   n.a.    ZOPICLONE 7.5MG TABLET                 NaN   \n",
       "46382   n.a.  ZOPICLONE ORAL 7.5MG/TAB                 NaN   \n",
       "\n",
       "                                                Hospital        Ward  \\\n",
       "0                           National University Hospital         A&E   \n",
       "1                           National University Hospital         A&E   \n",
       "2                           National University Hospital         A&E   \n",
       "3                           National University Hospital         A&E   \n",
       "4                           National University Hospital         A&E   \n",
       "...                                                  ...         ...   \n",
       "46377                            Mount Elizabeth Orchard  Outpatient   \n",
       "46379                       National University Hospital  HD Class A   \n",
       "46380                       National University Hospital    Class A1   \n",
       "46381                       National University Hospital  Outpatient   \n",
       "46382  The Harley Street Heart and Cancer Centre (Nov...  Outpatient   \n",
       "\n",
       "             Consultant PricingDate  Price Minimum Maximum  ...  Test  Year  \\\n",
       "0                   NaN  2020-01-01  121.0       5       5  ...   NaN  2020   \n",
       "1                   NaN  2019-01-11  121.0       5       5  ...   NaN  2019   \n",
       "2                   NaN  2020-01-02  121.0       5       5  ...   NaN  2020   \n",
       "3                   NaN  2020-01-03  121.0       5       5  ...   NaN  2020   \n",
       "4                   NaN  2020-01-05  121.0       5       5  ...   NaN  2020   \n",
       "...                 ...         ...    ...     ...     ...  ...   ...   ...   \n",
       "46377               NaN  2017-01-05   2.12       5       5  ...   NaN  2017   \n",
       "46379               NaN  2019-01-11   0.54       5       5  ...   NaN  2019   \n",
       "46380               NaN  2019-01-12   0.54       5       5  ...   NaN  2019   \n",
       "46381               NaN  2019-01-12   0.55       5       5  ...   NaN  2019   \n",
       "46382  Lo Soo Kien, Sue  2018-01-05    1.0       5       5  ...   NaN  2018   \n",
       "\n",
       "       tempmonth tempday Month ApplicationMethod Surgical_Procedure  \\\n",
       "0              1       1     1               NaN                      \n",
       "1              1      11    11               NaN                      \n",
       "2              1       2     2               NaN                      \n",
       "3              1       3     3               NaN                      \n",
       "4              1       5     5               NaN                      \n",
       "...          ...     ...   ...               ...                ...   \n",
       "46377          1       5     5               NaN                      \n",
       "46379          1      11    11               NaN                      \n",
       "46380          1      12    12               NaN                      \n",
       "46381          1      12    12               NaN                      \n",
       "46382          1       5     5               NaN                      \n",
       "\n",
       "      SpecificConsultant? Urgency? Care_Classification  \n",
       "0                      No       No          Outpatient  \n",
       "1                      No       No          Outpatient  \n",
       "2                      No       No          Outpatient  \n",
       "3                      No       No          Outpatient  \n",
       "4                      No       No          Outpatient  \n",
       "...                   ...      ...                 ...  \n",
       "46377                  No       No          Outpatient  \n",
       "46379                  No       No           Inpatient  \n",
       "46380                  No       No           Inpatient  \n",
       "46381                  No       No          Outpatient  \n",
       "46382                 Yes       No          Outpatient  \n",
       "\n",
       "[43818 rows x 37 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = len(filtered_data) * 0.1\n",
    "df_cleaned = filtered_data.dropna(thresh=threshold, axis=1)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9684db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1683806229.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Price'] = pd.to_numeric(df_cleaned['Price'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['Price'] = pd.to_numeric(df_cleaned['Price'], errors='coerce')\n",
    "hospital_price = df_cleaned.groupby(['Hospital', 'Year'])['Price'].mean().reset_index().sort_values(by=['Hospital', 'Year'])\n",
    "ward_price = df_cleaned.groupby(['Ward', 'Year'])['Price'].mean().reset_index().sort_values(by=['Ward', 'Year'])\n",
    "parent_price = df_cleaned.groupby(['Parent', 'Year'])['Price'].mean().reset_index().sort_values(by=['Parent', 'Year'])\n",
    "child_price = df_cleaned.groupby(['Child', 'Year'])['Price'].mean().reset_index().sort_values(by=['Child', 'Year'])\n",
    "sheet_name_price = df_cleaned.groupby(['Sheet_Name', 'Year'])['Price'].mean().reset_index().sort_values(by=['Sheet_Name', 'Year'])\n",
    "procedure_name_price = df_cleaned.groupby(['Procedure_Name', 'Year'])['Price'].mean().reset_index().sort_values(by=['Procedure_Name', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61c861ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of NaNs in each column:\n",
      "Test                    38859\n",
      "Route                   38552\n",
      "ApplicationMethod       37944\n",
      "Consultant              37202\n",
      "Dosage                  36043\n",
      "Form                    35821\n",
      "Footnotes               35610\n",
      "QuantityNotMoreThan     34105\n",
      "Period                  34105\n",
      "Condition               34104\n",
      "Footnote                31883\n",
      "Brand                   31061\n",
      "Company                 30019\n",
      "Type                    26671\n",
      "Code                     1091\n",
      "Maximum                     1\n",
      "Parent                      0\n",
      "Ward                        0\n",
      "Urgency?                    0\n",
      "SpecificConsultant?         0\n",
      "Surgical_Procedure          0\n",
      "Hospital                    0\n",
      "Month                       0\n",
      "tempday                     0\n",
      "tempmonth                   0\n",
      "Year                        0\n",
      "Sterile?                    0\n",
      "Child                       0\n",
      "Procedure_Name              0\n",
      "Disposable?                 0\n",
      "PricingDate                 0\n",
      "Price                       0\n",
      "Minimum                     0\n",
      "MaximumDailyQuantity        0\n",
      "Description                 0\n",
      "Sheet_Name                  0\n",
      "Care_Classification         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count = df_cleaned.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Count of NaNs in each column:\")\n",
    "print(nan_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09a67731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/2294111214.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['NLP'] = df_cleaned[['Description', 'Type', 'Hospital','Child','Sheet_Name','Footnote']].apply(concat_columns, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def concat_columns(row):\n",
    "    return ' '.join(str(item) for item in row)\n",
    "\n",
    "\n",
    "df_cleaned['NLP'] = df_cleaned[['Description', 'Type', 'Hospital','Child','Sheet_Name','Footnote']].apply(concat_columns, axis=1)\n",
    "\n",
    "descp = df_cleaned['NLP'].tolist()\n",
    "unique_desc = list(set(descp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e2d411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "\n",
    "for i in unique_desc:\n",
    "    s = i.split()\n",
    "    if s[0] not in cat:\n",
    "        cat.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b92b4231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nan', 58554), ('mount', 23455), ('elizabeth', 23434), ('novena', 19852), ('of', 12257), ('and', 11692), ('hospit', 11487), ('orchard', 9378), ('fee', 8919), ('for', 8892), ('the', 7380), ('cancer', 6573), ('univers', 6457), ('nation', 6400), ('treatment', 6397), ('centr', 5813), ('use', 5582), ('lab', 5347), ('parkway', 4833), ('in', 4571), ('to', 4423), ('with', 3583), ('consult', 3390), ('indic', 3163), ('inject', 3075), ('gener', 3055), ('as', 3038), ('biochemistri', 2937), ('infect', 2864), ('blood', 2566), ('charg', 2525), ('tablet', 2513), ('a', 2473), ('x', 2368), ('other', 2325), ('dress', 2242), ('set', 2219), ('skin', 2198), ('servic', 2195), ('singapor', 2177), ('consum', 2168), ('gleneagl', 2025), ('tube', 2022), ('sodium', 1904), ('patient', 1871), ('steril', 1848), ('therapi', 1736), ('chlorid', 1720), ('diseas', 1681), ('or', 1674), ('is', 1641), ('transfus', 1600), ('medic', 1580), ('pain', 1535), ('nurs', 1450), ('daili', 1368), ('intraven', 1357), ('acut', 1344), ('room', 1281), ('vitamin', 1257), ('procedur', 1230), ('ulcer', 1186), ('tab', 1182), ('albumin', 1180), ('agent', 1141), ('doctor', 1135), ('ot', 1133), ('inj', 1119), ('suction', 1086), ('tan', 1076), ('surgic', 1076), ('drug', 1076), ('1', 1069), ('surgeri', 1035), ('infus', 1031), ('glove', 1031), ('analges', 1028), ('seng', 1020), ('nutrit', 1018), ('tock', 1017), ('treat', 1017), ('microbiolog', 1014), ('respiratori', 1004), ('care', 983), ('prophylaxi', 983), ('2', 947), ('prevent', 943), ('associ', 939), ('process', 930), ('oral', 920), ('clinic', 911), ('chemo', 883), ('facil', 883), ('be', 866), ('also', 862), ('heart', 845), ('acid', 845), ('xray', 820), ('prepar', 815), ('bacteri', 814)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')  # For stemming\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_tokens = [porter.stem(token) for token in tokens if token.isalnum()]\n",
    "    return stemmed_tokens\n",
    "\n",
    "\n",
    "tokenized_and_stemmed_descriptions = df_cleaned['NLP'].apply(tokenize_and_stem)\n",
    "all_words = [word for sublist in tokenized_and_stemmed_descriptions for word in sublist]\n",
    "\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "\n",
    "common_words = word_counts.most_common()\n",
    "\n",
    "\n",
    "print(common_words[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58ce9213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Breast cancer',\n",
       " 'Abemaciclib',\n",
       " 'Others',\n",
       " 'Abiraterone',\n",
       " 'Leukaemia',\n",
       " 'Acalabrutinib',\n",
       " 'Lymphoma',\n",
       " 'Acalabrutinib plus obinutuzumab',\n",
       " 'Lung cancer',\n",
       " 'Colorectal cancer',\n",
       " 'Alectinib',\n",
       " 'Alpelisib',\n",
       " 'Myeloproliferative neoplasms',\n",
       " 'Anagrelide',\n",
       " 'Anastrozole',\n",
       " 'Prostate cancer',\n",
       " 'Apalutamide',\n",
       " 'Arsenic trioxide',\n",
       " 'Liver cancer',\n",
       " 'Atezolizumab',\n",
       " 'Atezolizumab plus bevacizumab biosimilar',\n",
       " 'Bladder cancer',\n",
       " 'Atezolizumab plus nab-paclitaxel',\n",
       " 'Atezolizumab plus bevacizumab',\n",
       " 'Avelumab',\n",
       " 'Merkel cell cancer',\n",
       " 'Renal cancer',\n",
       " 'Axitinib',\n",
       " 'Azacitidine',\n",
       " 'Bacillus Calmette-Guerin (BCG)',\n",
       " 'Bendamustine',\n",
       " 'Bevacizumab',\n",
       " 'Bevacizumab biosimilar',\n",
       " 'Bexarotene',\n",
       " 'Bicalutamide',\n",
       " 'Bleomycin',\n",
       " 'Blinatumomab',\n",
       " 'Bortezomib',\n",
       " 'Brentuximab vedotin',\n",
       " 'Brigatinib',\n",
       " 'Bromocriptine',\n",
       " 'Busulfan',\n",
       " 'Cabazitaxel',\n",
       " 'Neuroendocrine',\n",
       " 'Cabozantinib',\n",
       " 'Capecitabine',\n",
       " 'Carboplatin',\n",
       " 'Multiple myeloma',\n",
       " 'Carfilzomib',\n",
       " 'Carmustine',\n",
       " 'Ceritinib',\n",
       " 'Cetuximab',\n",
       " 'Chlorambucil',\n",
       " 'Cisplatin',\n",
       " 'Cladribine',\n",
       " 'Copanlisib',\n",
       " 'Crisantaspase',\n",
       " 'Crizotinib',\n",
       " 'Cyclophosphamide',\n",
       " 'Cyproterone',\n",
       " 'Cytarabine',\n",
       " 'Dabrafenib plus trametinib',\n",
       " 'Skin cancer',\n",
       " 'Thyroid cancer',\n",
       " 'Dacarbazine',\n",
       " 'Dacomitinib',\n",
       " 'Dactinomycin',\n",
       " 'Daratumumab',\n",
       " 'Darolutamide',\n",
       " 'Dasatinib',\n",
       " 'Daunorubicin',\n",
       " 'Decitabine',\n",
       " 'Degarelix',\n",
       " 'Desmopressin',\n",
       " 'Dexamethasone',\n",
       " 'Dinutuximab beta',\n",
       " 'Docetaxel',\n",
       " 'Endometrial cancer',\n",
       " 'Doxorubicin',\n",
       " 'Durvalumab',\n",
       " 'Upper gastrointestinal cancer',\n",
       " 'Encorafenib',\n",
       " 'Enfortumab vedotin',\n",
       " 'Entrectinib',\n",
       " 'Tumour agnostic',\n",
       " 'Enzalutamide',\n",
       " 'Epirubicin',\n",
       " 'Erdafitinib',\n",
       " 'Eribulin mesylate',\n",
       " 'Sarcoma',\n",
       " 'Erlotinib',\n",
       " 'Etoposide',\n",
       " 'Everolimus',\n",
       " 'Exemestane',\n",
       " 'Fedratinib',\n",
       " 'Fludarabine',\n",
       " 'Fluorouracil',\n",
       " 'Flutamide',\n",
       " 'Folinic acid',\n",
       " 'Fulvestrant',\n",
       " 'Gefitinib',\n",
       " 'Gemcitabine',\n",
       " 'Gemtuzumab ozogamicin',\n",
       " 'Gilteritinib',\n",
       " 'Goserelin acetate',\n",
       " 'Hydroxyurea',\n",
       " 'Ibrutinib plus rituximab',\n",
       " 'Ibrutinib plus obinutuzumab',\n",
       " 'Ibrutinib',\n",
       " 'Idarubicin',\n",
       " 'Idelalisib',\n",
       " 'Ifosfamide',\n",
       " 'Imatinib',\n",
       " 'Imiquimod',\n",
       " 'Inotuzumab ozogamicin',\n",
       " 'Interferon alfa 2a',\n",
       " 'Irinotecan hydrochloride',\n",
       " 'Isatuximab plus pomalidomide',\n",
       " 'Isatuximab plus carfilzomib',\n",
       " 'Ixazomib',\n",
       " 'Lanreotide',\n",
       " 'Lapatinib',\n",
       " 'Larotrectinib',\n",
       " 'L-asparaginase',\n",
       " 'Lenalidomide',\n",
       " 'Lenvatinib',\n",
       " 'Lenvatinib plus everolimus',\n",
       " 'Letrozole',\n",
       " 'Leuprorelin acetate',\n",
       " 'Liposomal doxorubicin',\n",
       " 'Pancreatic cancer',\n",
       " 'Lomustine',\n",
       " 'Lorlatinib',\n",
       " 'Lurbinectedin',\n",
       " 'Lutetium PSMA',\n",
       " 'Lutetium-177 peptide',\n",
       " 'Megestrol',\n",
       " 'Melphalan',\n",
       " 'Mercaptopurine',\n",
       " 'Meta-iodobenzylguanidine',\n",
       " 'Methotrexate',\n",
       " 'Methylprednisolone',\n",
       " 'Midostaurin',\n",
       " 'Mitomycin',\n",
       " 'Mitotane',\n",
       " 'Mitoxantrone',\n",
       " 'Nab-paclitaxel',\n",
       " 'Nelarabine',\n",
       " 'Neratinib',\n",
       " 'Nilotinib',\n",
       " 'Ovarian cancer',\n",
       " 'Niraparib',\n",
       " 'Head and neck cancer',\n",
       " 'Nivolumab',\n",
       " 'Nivolumab plus cabozantinib',\n",
       " 'Nivolumab plus ipilimumab',\n",
       " 'Thoracic cancer',\n",
       " 'Obinutuzumab',\n",
       " 'Octreotide',\n",
       " 'Olaparib',\n",
       " 'Olaparib plus bevacizumab biosimilar',\n",
       " 'Olaparib plus bevacizumab',\n",
       " 'Osimertinib',\n",
       " 'Oxaliplatin',\n",
       " 'Paclitaxel',\n",
       " 'Palbociclib',\n",
       " 'Panitumumab',\n",
       " 'Pazopanib',\n",
       " 'Pegaspargase\\xa0',\n",
       " 'Pembrolizumab',\n",
       " 'Cervical cancer',\n",
       " 'Pembrolizumab plus axitinib',\n",
       " 'Pembrolizumab plus lenvatinib',\n",
       " 'Pemetrexed',\n",
       " 'Pemigatinib',\n",
       " 'Pertuzumab plus trastuzumab',\n",
       " 'Pertuzumab + Trastuzumab',\n",
       " 'Polatuzumab vedotin plus rituximab biosimilar',\n",
       " 'Polatuzumab vedotin plus rituximab',\n",
       " 'Pomalidomide',\n",
       " 'Ponatinib',\n",
       " 'Prednisolone',\n",
       " 'Procarbazine',\n",
       " 'Radium-223',\n",
       " 'Ramucirumab',\n",
       " 'Regorafenib',\n",
       " 'Ribociclib',\n",
       " 'Ripretinib',\n",
       " 'Rituximab',\n",
       " 'Rituximab biosimilar',\n",
       " 'Romidepsin',\n",
       " 'Ruxolitinib',\n",
       " 'Sacituzumab govitecan',\n",
       " 'Selinexor',\n",
       " \"Multicentric Castleman's disease\",\n",
       " 'Sodium iodide',\n",
       " 'Somatropin',\n",
       " 'Sorafenib',\n",
       " 'Streptozocin',\n",
       " 'Sunitinib',\n",
       " 'Talazoparib',\n",
       " 'Tamoxifen',\n",
       " 'Tegafur + gimeracil + oteracil',\n",
       " 'Temozolomide',\n",
       " 'Tepotinib',\n",
       " 'Thalidomide',\n",
       " 'Thiotepa',\n",
       " 'Tioguanine',\n",
       " 'Topotecan',\n",
       " 'Trabectedin',\n",
       " 'Trastuzumab',\n",
       " 'Trastuzumab biosimilar',\n",
       " 'Trastuzumab deruxtecan',\n",
       " nan,\n",
       " 'Trastuzumab emtansine',\n",
       " 'Tretinoin',\n",
       " 'Trifluridine + tipiracil',\n",
       " 'Triptorelin',\n",
       " 'Tucatinib plus trastuzumab',\n",
       " 'Venetoclax',\n",
       " 'Venetoclax plus rituximab',\n",
       " 'Venetoclax plus obinutuzumab',\n",
       " 'Vinblastine sulfate',\n",
       " 'Vincristine sulfate',\n",
       " 'Vinflunine',\n",
       " 'Vinorelbine',\n",
       " 'Vismodegib',\n",
       " 'Zanubrutinib']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_excel_file = 'cancer_list.xlsx'\n",
    "cancer_list = pd.read_excel(get_excel_file)\n",
    "sub_cancer_list = cancer_list.copy()\n",
    "cols = ['Cancer type', 'Active ingredient']\n",
    "sub_cancer_list = sub_cancer_list[cols]\n",
    "sub_cancer_list.dropna(subset=['Cancer type'], inplace=True)\n",
    "cancer_word_list = []\n",
    "\n",
    "for cancer_type, ingredient in sub_cancer_list.itertuples(index=False):\n",
    "    if cancer_type not in cancer_word_list:\n",
    "        cancer_word_list.append(cancer_type)\n",
    "    elif ingredient not in cancer_word_list:\n",
    "        cancer_word_list.append(ingredient)\n",
    "\n",
    "cancer_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfaa8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"cancerdrugsdb.txt\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_contents = file.read()\n",
    "        splits = file_contents.split(\"\\t\")\n",
    "        col_header = splits[0:14]\n",
    "        datas = splits[14: len(splits)]\n",
    "\n",
    "except:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ddcc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_columns = len(col_header)\n",
    "num_rows = len(datas) // num_columns\n",
    "listB_reshaped = [datas[i:i+num_columns] for i in range(0, len(datas), num_columns)]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(listB_reshaped, columns=col_header)\n",
    "\n",
    "for i in df[\"Product\"]:\n",
    "    if i not in cancer_word_list:\n",
    "        cancer_word_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32de73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = df['Indications'].tolist()\n",
    "filtered_list = [x for x in my_list if x is not None]\n",
    "\n",
    "for i in filtered_list:\n",
    "    if \";\" in i:\n",
    "        splits = i.split(\";\")\n",
    "        for j in splits:\n",
    "            if j not in cancer_word_list:\n",
    "                cancer_word_list.append(j)\n",
    "    else:\n",
    "         if j not in cancer_word_list:\n",
    "             cancer_word_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72de744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords =['cancer','chemo','radiotherapy','endocrine','hormonal','immunotherapy','target','biopsy',\"immunotherapy\", \"radiosurgery\", \"metastasis\", \"benign\", \"screening\", \"exam\"\n",
    "           \"guided biopsy\", \"biopsy complex exam\", \"biopsy Simple Exam\",  \"Complex Biopsy\", \"Simple Biopsy\", \"Reusable Hot Biopsy Forcep\",\n",
    "            \"Biopsy forceps\", \"3 (13-18 Pcs) Gastric Biopsy\", \"Specialist Biopsy 1st Specimen Only\", \"Specialist Biopsy\", \"Guided Core Biopsy\"\n",
    "            ,\"Biopsy\", \"OGD Biopsy Forcep\" \"Hot Biopsy forceps\" \"Disposable Biopsy forceps\" ,'Core Biopsy','Radiosurgery','Oncology',\n",
    "            'Chemotherapy','core','specimen','leukemia' , 'leukaemia' , \"filgrastim\", \"tumour\",\"tumors\",\"tumor\", \"cytology\", \"chemotherapy-induced\", \"Ondansetron\"\n",
    "            ]\n",
    "\n",
    "keyword = keywords #+ cancer_word_list temp remove this \n",
    "\n",
    "lowercase = [str(item).lower() if isinstance(item, str) else item for item in keyword]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3068a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_list = []\n",
    "\n",
    "\n",
    "for i in lowercase:\n",
    "    splits = str(i).split()\n",
    "    if len(splits) > 1:\n",
    "        for j in splits:\n",
    "            lowercase_list.append(j)\n",
    "    else:\n",
    "        lowercase_list.append(i)\n",
    "\n",
    "\n",
    "\n",
    "common_words = {'a','b', 'and', 'or', 'the','for', 'with', 'not', 'by', 'ii','iii','system','is', 'of', 'in', 'on', 'at', 'to','1','2','3','4','5','6','7','8','9','12','surgery','1st','2a','3b','c','t3','t4','treatment','type'}\n",
    "\n",
    "# Input list\n",
    "\n",
    "# Remove common words from the input list\n",
    "lowercase_list2 = [word for word in lowercase_list if word not in common_words]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b303db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(lst):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "unique_list = remove_duplicates(lowercase_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67d62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "250c1e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/xenang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/4166229139.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Tokens'], df_cleaned['Stemmed'], df_cleaned['Lemmatized'] = zip(*df_cleaned['NLP'].apply(process_text))\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/4166229139.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Tokens'], df_cleaned['Stemmed'], df_cleaned['Lemmatized'] = zip(*df_cleaned['NLP'].apply(process_text))\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/4166229139.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Tokens'], df_cleaned['Stemmed'], df_cleaned['Lemmatized'] = zip(*df_cleaned['NLP'].apply(process_text))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# Sample DataFrame\n",
    "# df_cleaned = pd.DataFrame({'Description': ['Some text about cancer and chemo.', 'Another text mentioning radiotherapy.', 'Description with no keyword.']})\n",
    "\n",
    "# Assuming df_cleaned is your DataFrame with the 'Description' column\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [remove_punctuation(token.lower()) for token in tokens if token.isalnum()]  # Remove punctuation and convert to lowercase\n",
    "    stemmed_tokens = [porter.stem(token) for token in tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    return tokens, stemmed_tokens, lemmatized_tokens\n",
    "\n",
    "\n",
    "def get_wordnet_pos(token):\n",
    "    tag = nltk.pos_tag([token])[0][1][0].upper()  # Get the POS tag\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)  # Return NOUN if not found\n",
    "\n",
    "\n",
    "df_cleaned['Tokens'], df_cleaned['Stemmed'], df_cleaned['Lemmatized'] = zip(*df_cleaned['NLP'].apply(process_text))\n",
    "\n",
    "\n",
    "def check_keywords(tokens):\n",
    "    cancerlist = []\n",
    "    for token in tokens:\n",
    "        if token in unique_list:\n",
    "            cancerlist.append(token)\n",
    "    \n",
    "    return cancerlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3497454",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lowercase_list2)\n",
    "\n",
    "df = pd.DataFrame(lowercase_list2, columns=['Fruit'])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('fruits.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b3f9a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1055050893.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Keywords_Present'] = df_cleaned['Tokens'].apply(check_keywords)\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1055050893.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Keywords_Present2'] = df_cleaned['Stemmed'].apply(check_keywords)\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1055050893.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Keywords_Present3'] = df_cleaned['Lemmatized'].apply(check_keywords)\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1055050893.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['is_non_empty'] = df_cleaned['Keywords_Present'].apply(is_empty)\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1055050893.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['is_non_empty2'] = df_cleaned['Keywords_Present2'].apply(is_empty)\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1055050893.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['is_non_empty3'] = df_cleaned['Keywords_Present3'].apply(is_empty)\n",
      "/var/folders/sp/84j13ybj0zd_p4y410zpx7jc0000gn/T/ipykernel_53419/1055050893.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Cancer'] = df_cleaned['is_non_empty'] + df_cleaned['is_non_empty2'] + df_cleaned['is_non_empty3'] #+ df_cleaned['is_non_empty4']\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['Keywords_Present'] = df_cleaned['Tokens'].apply(check_keywords)\n",
    "df_cleaned['Keywords_Present2'] = df_cleaned['Stemmed'].apply(check_keywords)\n",
    "df_cleaned['Keywords_Present3'] = df_cleaned['Lemmatized'].apply(check_keywords)\n",
    "#df_cleaned['Keywords_Present4'] = df_cleaned['NLP'].apply(check_keywords)\n",
    "#df_cleaned['Cancer'] = df_cleaned['Keywords_Present'] + df_cleaned['Keywords_Present2'] + df_cleaned['Keywords_Present3'] + df_cleaned['Keywords_Present4']\n",
    "\n",
    "def is_empty(lst):\n",
    "    if len(lst) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df_cleaned['is_non_empty'] = df_cleaned['Keywords_Present'].apply(is_empty)\n",
    "df_cleaned['is_non_empty2'] = df_cleaned['Keywords_Present2'].apply(is_empty)\n",
    "df_cleaned['is_non_empty3'] = df_cleaned['Keywords_Present3'].apply(is_empty)\n",
    "#df_cleaned['is_non_empty4'] = df_cleaned['Keywords_Present4'].apply(is_empty)\n",
    "\n",
    "df_cleaned['Cancer'] = df_cleaned['is_non_empty'] + df_cleaned['is_non_empty2'] + df_cleaned['is_non_empty3'] #+ df_cleaned['is_non_empty4']\n",
    "columns_to_drop = ['is_non_empty', 'is_non_empty2','is_non_empty3','Tokens','Stemmed','Lemmatized']\n",
    "df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "397cc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been written to Output/combined_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Specify the path for the new Excel file\n",
    "output_excel_path = 'Output/combined_data.xlsx'\n",
    " \n",
    "# Write the combined dataframe to a new Excel file\n",
    "df_cleaned.to_excel(output_excel_path, index=False)\n",
    "\n",
    "# Display a message indicating the success\n",
    "print(f\"Combined data has been written to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3e5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e53a15d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'breaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m breaker\n",
      "\u001b[0;31mNameError\u001b[0m: name 'breaker' is not defined"
     ]
    }
   ],
   "source": [
    "breaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8cb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>fyear</th>\n",
       "      <th>datadate</th>\n",
       "      <th>ceq</th>\n",
       "      <th>xstfws</th>\n",
       "      <th>conm</th>\n",
       "      <th>gsector</th>\n",
       "      <th>pct_chng</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8546</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>11870.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>KONINKLIJKE PHILIPS NV</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.560941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8546</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>14438.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>KONINKLIJKE PHILIPS NV</td>\n",
       "      <td>35</td>\n",
       "      <td>-38.461538</td>\n",
       "      <td>81.816848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8546</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>13249.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>KONINKLIJKE PHILIPS NV</td>\n",
       "      <td>35</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16602</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>-24.776</td>\n",
       "      <td>9.136</td>\n",
       "      <td>THE IQ GROUP GLOBAL LTD</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.560941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16602</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>-6.960</td>\n",
       "      <td>8.309</td>\n",
       "      <td>THE IQ GROUP GLOBAL LTD</td>\n",
       "      <td>35</td>\n",
       "      <td>-9.052102</td>\n",
       "      <td>81.816848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8654</th>\n",
       "      <td>359880</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>441.991</td>\n",
       "      <td>86.613</td>\n",
       "      <td>ACCENT MICROCELL LIMITED</td>\n",
       "      <td>35</td>\n",
       "      <td>-6.370398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657</th>\n",
       "      <td>360003</td>\n",
       "      <td>2019</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1078.580</td>\n",
       "      <td>202.264</td>\n",
       "      <td>INNOVA CAPTAB LIMITED</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8658</th>\n",
       "      <td>360003</td>\n",
       "      <td>2020</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>1448.210</td>\n",
       "      <td>223.340</td>\n",
       "      <td>INNOVA CAPTAB LIMITED</td>\n",
       "      <td>35</td>\n",
       "      <td>10.420045</td>\n",
       "      <td>2.560941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8659</th>\n",
       "      <td>360003</td>\n",
       "      <td>2021</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2086.060</td>\n",
       "      <td>404.590</td>\n",
       "      <td>INNOVA CAPTAB LIMITED</td>\n",
       "      <td>35</td>\n",
       "      <td>81.154294</td>\n",
       "      <td>81.816848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8660</th>\n",
       "      <td>360003</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>2844.000</td>\n",
       "      <td>547.970</td>\n",
       "      <td>INNOVA CAPTAB LIMITED</td>\n",
       "      <td>35</td>\n",
       "      <td>35.438345</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2518 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gvkey  fyear    datadate        ceq   xstfws                      conm  \\\n",
       "6       8546   2020  2020-12-31  11870.000   13.000    KONINKLIJKE PHILIPS NV   \n",
       "7       8546   2021  2021-12-31  14438.000    8.000    KONINKLIJKE PHILIPS NV   \n",
       "8       8546   2022  2022-12-31  13249.000   10.000    KONINKLIJKE PHILIPS NV   \n",
       "17     16602   2020  2020-06-30    -24.776    9.136   THE IQ GROUP GLOBAL LTD   \n",
       "18     16602   2021  2021-06-30     -6.960    8.309   THE IQ GROUP GLOBAL LTD   \n",
       "...      ...    ...         ...        ...      ...                       ...   \n",
       "8654  359880   2022  2023-03-31    441.991   86.613  ACCENT MICROCELL LIMITED   \n",
       "8657  360003   2019  2020-03-31   1078.580  202.264     INNOVA CAPTAB LIMITED   \n",
       "8658  360003   2020  2021-03-31   1448.210  223.340     INNOVA CAPTAB LIMITED   \n",
       "8659  360003   2021  2022-03-31   2086.060  404.590     INNOVA CAPTAB LIMITED   \n",
       "8660  360003   2022  2023-03-31   2844.000  547.970     INNOVA CAPTAB LIMITED   \n",
       "\n",
       "      gsector   pct_chng      value  \n",
       "6          35   0.000000   2.560941  \n",
       "7          35 -38.461538  81.816848  \n",
       "8          35  25.000000        NaN  \n",
       "17         35   0.000000   2.560941  \n",
       "18         35  -9.052102  81.816848  \n",
       "...       ...        ...        ...  \n",
       "8654       35  -6.370398        NaN  \n",
       "8657       35   0.000000   0.000000  \n",
       "8658       35  10.420045   2.560941  \n",
       "8659       35  81.154294  81.816848  \n",
       "8660       35  35.438345        NaN  \n",
       "\n",
       "[2518 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = pd.read_csv('salary.csv')\n",
    "salary = salary[salary['xstfws'].notna()]\n",
    "salary['fyear'] = salary['fyear'].astype(int)\n",
    "\n",
    "salary.loc[:,'pct_chng'] = salary.groupby('conm')['xstfws'].pct_change().fillna(0) *100\n",
    "nan_rows = salary[salary['pct_chng'].isna()]\n",
    "nan_rows\n",
    "result = salary.groupby(salary['fyear'])['pct_chng'].mean()\n",
    "salary['value'] = salary.groupby('fyear')['pct_chng'].transform('mean')\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cfdc15f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Raffles', 'SGH', 'AALC', 'Parkway', 'NUH', 'TTSH']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "hosp_lists = os.listdir(\"OCR\")\n",
    "hospitalname = []\n",
    "\n",
    "for i in hosp_lists:\n",
    "    sep = i.split()\n",
    "    sep2 = sep[3].split(\".\")\n",
    "    hospitalname.append(sep2[0])\n",
    "hospitalname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2fc06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for hospitals in hosp_lists:\n",
    "    excel_file_path = \"OCR/\" + hospitals\n",
    "\n",
    "    all_sheets = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "    sep = hospitals.split()\n",
    "    sep2 = sep[3].split(\".\")\n",
    "    hospitalname = sep2[0]\n",
    "\n",
    "\n",
    "    for sheet_name, sheet_df in all_sheets.items():\n",
    "        sheet_df['Codes'] = sheet_name\n",
    "        sheet_df['Hospitals'] = hospitalname\n",
    "        try:\n",
    "            combined_df = pd.concat([combined_df, sheet_df], ignore_index=True)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing sheet '{sheet_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c78a080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n"
     ]
    }
   ],
   "source": [
    "combined_df['Heading'].fillna(combined_df['Code'], inplace=True)\n",
    "\n",
    "print(\"check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e33c4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df['NLP'] = combined_df[['Provider', 'Type', 'Heading','Description','Category','LOG Dx']].apply(concat_columns, axis=1)\n",
    "\n",
    "combined_df['Tokens'], combined_df['Stemmed'], combined_df['Lemmatized'] = zip(*combined_df['NLP'].apply(process_text))\n",
    "\n",
    "df_cleaned = combined_df\n",
    "\n",
    "df_cleaned['Keywords_Present'] = df_cleaned['Tokens'].apply(check_keywords)\n",
    "df_cleaned['Keywords_Present2'] = df_cleaned['Stemmed'].apply(check_keywords)\n",
    "df_cleaned['Keywords_Present3'] = df_cleaned['Lemmatized'].apply(check_keywords)\n",
    "#df_cleaned['Keywords_Present4'] = df_cleaned['NLP'].apply(check_keywords)\n",
    "#df_cleaned['Cancer'] = df_cleaned['Keywords_Present'] + df_cleaned['Keywords_Present2'] + df_cleaned['Keywords_Present3'] + df_cleaned['Keywords_Present4']\n",
    "\n",
    "def is_empty(lst):\n",
    "    if len(lst) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df_cleaned['is_non_empty'] = df_cleaned['Keywords_Present'].apply(is_empty)\n",
    "df_cleaned['is_non_empty2'] = df_cleaned['Keywords_Present2'].apply(is_empty)\n",
    "df_cleaned['is_non_empty3'] = df_cleaned['Keywords_Present3'].apply(is_empty)\n",
    "#df_cleaned['is_non_empty4'] = df_cleaned['Keywords_Present4'].apply(is_empty)\n",
    "\n",
    "df_cleaned['Cancer'] = df_cleaned['is_non_empty'] + df_cleaned['is_non_empty2'] + df_cleaned['is_non_empty3'] #+ df_cleaned['is_non_empty4']\n",
    "columns_to_drop = ['is_non_empty', 'is_non_empty2','is_non_empty3','Tokens','Stemmed','Lemmatized']\n",
    "df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714dc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0df9e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been written to Output/OCR_excel.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Specify the path for the new Excel file\n",
    "output_excel_path = 'Output/OCR_excel.xlsx'\n",
    "\n",
    "# Write the combined dataframe to a new Excel file\n",
    "df_cleaned.to_excel(output_excel_path, index=False)\n",
    "\n",
    "# Display a message indicating the success\n",
    "print(f\"Combined data has been written to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7764f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
