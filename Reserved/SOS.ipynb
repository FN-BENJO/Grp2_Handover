{"cells":[{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\felic\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"data":{"text/plain":["True"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder \n","import os\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from nltk.corpus import wordnet\n","import string\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["ocr_excel = pd.read_excel('Output/OCR_excel.xlsx')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["codes = ocr_excel['Codes']\n","sn = ocr_excel['S/N']\n","gender = ocr_excel['Gender']\n","name = ocr_excel['NAME']"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["ocr_excel.drop(ocr_excel[((codes == '700') & (sn == 381)) | ((gender.isna()) & (name.isna()))].index, inplace=True)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\felic\\AppData\\Local\\Temp\\ipykernel_6556\\1320310970.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  gender.loc[name.isin(['F', 'M'])] = gender[name.isin(['F', 'M'])].fillna(name)\n"]}],"source":["gender = ocr_excel['Gender']\n","gender.loc[name.isin(['F', 'M'])] = gender[name.isin(['F', 'M'])].fillna(name)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["name = ocr_excel['NAME']\n","name.replace('F', np.NaN, inplace=True)\n","name.replace('M', np.NaN, inplace=True)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["ocr_excel['Type'].replace('OUPATIENT', 'OUTPATIENT', inplace=True)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for index, row in ocr_excel.iterrows():\n","    if pd.isna(row['Gender']):\n","        matching_rows = ocr_excel.loc[codes == row['Codes']]\n","        for _, matching_row in matching_rows.iterrows():\n","            if not pd.isna(matching_row['Gender']):\n","                ocr_excel.at[index, 'DOB'] = matching_row['DOB']\n","                break"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ocr_excel.loc[gender.isnull(), 'Gender'] = \\\n","    ocr_excel.loc[gender.isnull(), 'Codes'].map(\n","        ocr_excel.dropna(subset=['Gender']).set_index('Codes')['Gender'].to_dict()\n","    )"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def extract_year_from_date(date_string):\n","    if isinstance(date_string, int):\n","        return date_string\n","    date_obj = pd.to_datetime(date_string, errors='coerce')\n","    if not pd.isnull(date_obj):\n","        return date_obj.year\n","    else:\n","        return None\n","\n","ocr_excel['DOB'] = ocr_excel['DOB'].apply(extract_year_from_date)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["ocr_excel['DOB'] = ocr_excel['DOB'].fillna(ocr_excel.groupby('Codes')['DOB'].transform('last'))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from datetime import datetime\n","\n","current_year = datetime.now().year\n","ocr_excel['Age'] = current_year - ocr_excel['DOB']\n","dob_index = ocr_excel.columns.get_loc('DOB')\n","ocr_excel.insert(dob_index + 1, 'Age', ocr_excel.pop('Age'))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["ocr_excel['Qty'].fillna(ocr_excel['Qty'], inplace = True)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["ocr_excel['Subtotal GST'].fillna(ocr_excel['Subtotal']*1.07, inplace = True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['S/N', 'Gender', 'DOB', 'Age', 'Consultant', 'Provider', 'Type',\n","       'Ward Type', 'Invoice No. ', 'Heading', 'Date ', 'Code', 'Description',\n","       'Qty', 'Total Price', 'Unit Price', 'w GST', 'Subtotal', 'Codes',\n","       'Hospitals', 'LOG Dx', 'Pt. Ref. No.', 'NAME', 'Subtotal GST',\n","       'Invoice Period', 'NLP', 'Keywords_Present', 'Keywords_Present2',\n","       'Keywords_Present3', 'Cancer', 'Year', 'tempmonth', 'tempday', 'Month'],\n","      dtype='object')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["ocr_excel.columns"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["ocr_excel['Heading'].fillna(ocr_excel['Heading'], inplace = True)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#index_to_drop = [17, 25] + list(range(27, 31))\n","#ocr_excel.drop(ocr_excel.columns[index_to_drop], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["#ocr_excel.to_excel('OCR_excel (1).xlsx', index=False)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["combined_df = ocr_excel\n","\n","combined_df['Date '] = pd.to_datetime(combined_df['Date '], errors='coerce')\n","combined_df = combined_df.dropna(subset=['Date '])\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["combined_df['Date '] = pd.to_datetime(combined_df['Date '])\n","\n","combined_df['Year'] = combined_df['Date '].dt.year\n","combined_df['Month'] = combined_df['Date '].dt.month\n","combined_df['Day'] = combined_df['Date '].dt.day\n","\n","#combined_df['Month'] = np.where((combined_df['tempmonth'] == 1) & (combined_df['tempday'] == 1), 1, np.maximum(combined_df['tempmonth'], combined_df['tempday']))\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["combined_df = combined_df[(combined_df['Year'] >= 2016) & (combined_df['Year'] <= 2020)]"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def concat_columns(row):\n","    return ' '.join(str(item) for item in row)\n","\n","combined_df['NLP'] = combined_df[['Provider', 'Heading', 'Code', 'Description', 'LOG Dx']].apply(concat_columns, axis=1)\n","\n","descp = combined_df['NLP'].tolist()\n","unique_desc = list(set(descp))\n","\n","cat = []\n","\n","for i in unique_desc:\n","    s = i.split()\n","    if s[0] not in cat:\n","        cat.append(s[0])"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["get_ma_list = []\n","\n","for i in unique_desc:\n","    s = i.split()\n","    \n","    for get_str in s:\n","       if get_str.endswith('oma') and get_str not in get_ma_list:\n","          get_ma_list.append(get_str)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["get_ma_list = list(set([x.lower() for x in get_ma_list]))\n","get_ma_list = get_ma_list"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["['stoma',\n"," 'cholangiocarcinoma',\n"," '&stoma',\n"," 'osteosarcoma',\n"," 'gluacoma',\n"," 'lymphangioma',\n"," 'pheochromocytoma',\n"," 'schwannoma',\n"," 'astrocytoma',\n"," 'carcinoma',\n"," 'glioblastoma',\n"," 'glaucoma',\n"," 'adenocarcinoma',\n"," 'liposarcoma',\n"," 'neurofibroma',\n"," 'cholanglocarcinoma',\n"," 'myoma',\n"," 'medullablastoma',\n"," 'medulloblastoma',\n"," 'lymphoma',\n"," 'seroma',\n"," 'melanoma',\n"," 'myeloma',\n"," 'retinoblastoma',\n"," 'rhabdomyosarcoma',\n"," 'sarcoma',\n"," 'glioma']"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["get_ma_list"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["get_excel_file = 'Input/cancer_list.xlsx'\n","cancer_list = pd.read_excel(get_excel_file)\n","cancer_word_list = []\n","\n","for cancer_type in cancer_list['Cancer type'].dropna():\n","    if cancer_type not in cancer_word_list:\n","        cancer_word_list.append(cancer_type)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["keywords =['cancer','chemo','radiotherapy','endocrine','hormonal','immunotherapy',\"immunotherapy\", \"metastasis\", \"benign\",\n","         \"forceps\",\"viopsy\",'Radiosurgery','Oncology', \"LABORATORY \", 'Chemotherapy','core','specimen','leukemia' , \n","         'leukaemia' , \"filgrastim\", \"tumour\",\"tumors\",\"tumor\", \"cytology\", \"chemotherapy-induced\", \"Ondansetron\",\"lymphangiosarcoma\"\n","            ]\n","\n","keyword = keywords + cancer_word_list + get_ma_list\n","#len(keyword)\n","\n","lowercase = [str(item).lower() if isinstance(item, str) else item for item in keyword]\n","\n","lowercase_list = lowercase\n","\n","common_words = {'a','b', 'and', 'or', 'the','for', 'with', 'not', 'by', 'ii','iii','system','is', 'of', \n","                'in', 'on', 'at', 'to','1','2','3','4','5','6','7','8','9','12','surgery','1st','2a','3b','complex',\n","                'c','t3','t4','treatment','type','during','only','core','exam','screening','others','others ','&stoma','stoma','glaucoma','myoma'}\n","\n","# Input list\n","\n","# Remove common words from the input list\n","lowercase_list2 = [word for word in lowercase_list if word not in common_words]\n","\n","def remove_duplicates(lst):\n","    seen = set()\n","    result = []\n","    for item in lst:\n","        if item not in seen:\n","            seen.add(item)\n","            result.append(item)\n","    return result\n","\n","\n","unique_list = remove_duplicates(lowercase_list2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\felic/nltk_data'\n    - 'c:\\\\Users\\\\felic\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\felic\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\felic\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\felic\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6556\\2983470760.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mcombined_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Stemmed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lemmatized'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NLP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \"\"\"\n\u001b[1;32m-> 4433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m     def _reduce(\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6556\\2983470760.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mremove_punctuation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalnum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mstemmed_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\felic\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\felic/nltk_data'\n    - 'c:\\\\Users\\\\felic\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\felic\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\felic\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\felic\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"]}],"source":["def remove_punctuation(text):\n","    return ''.join([char for char in text if char not in string.punctuation])\n","\n","\n","porter = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","\n","\n","def process_text(text):\n","    tokens = word_tokenize(text)\n","    tokens = [remove_punctuation(token.lower()) for token in tokens if token.isalnum()]\n","    stemmed_tokens = [porter.stem(token) for token in tokens]\n","    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n","    return tokens, stemmed_tokens, lemmatized_tokens\n","\n","\n","def get_wordnet_pos(token):\n","    tag = nltk.pos_tag([token])[0][1][0].upper()\n","    tag_dict = {\"J\": wordnet.ADJ,\n","                \"N\": wordnet.NOUN,\n","                \"V\": wordnet.VERB,\n","                \"R\": wordnet.ADV}\n","    return tag_dict.get(tag, wordnet.NOUN)\n","\n","\n","combined_df['Tokens'], combined_df['Stemmed'], combined_df['Lemmatized'] = zip(*combined_df['NLP'].apply(process_text))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def concatenate_list(my_list):\n","    concatenated_string = \"\"\n","    for element in my_list:\n","        concatenated_string += str(element) + \" \"\n","    return concatenated_string\n","\n","def check_keywords(tokens):\n","    cancerlist = []\n","    for token in tokens:\n","        if token in unique_list:\n","            cancerlist.append(token)\n","    return concatenate_list(cancerlist)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["\"\\ndef check_keywords(tokens):\\n    cancerlist = []\\n    repeatlists = ['cancer','chemo','chemotherapy','biopsy']\\n    counter = 0\\n    result_list = []\\n\\n    for token in tokens:\\n        if token in unique_list:\\n            cancerlist.append(token)\\n\\n    for i in cancer_list:\\n        for r in repeatlists:\\n            if r in i:\\n                counter += 1\\n        if counter >=1:\\n            for item in cancerlist:\\n                if item not in repeatlists:\\n                    result_list.append(item)\\n\\n            return result_list\\n        else:\\n            return cancer_list\\n\""]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","def check_keywords(tokens):\n","    cancerlist = []\n","    repeatlists = ['cancer','chemo','chemotherapy','biopsy']\n","    counter = 0\n","    result_list = []\n","\n","    for token in tokens:\n","        if token in unique_list:\n","            cancerlist.append(token)\n","\n","    for i in cancer_list:\n","        for r in repeatlists:\n","            if r in i:\n","                counter += 1\n","        if counter >=1:\n","            for item in cancerlist:\n","                if item not in repeatlists:\n","                    result_list.append(item)\n","\n","            return result_list\n","        else:\n","            return cancer_list\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cleaned = combined_df\n","\n","df_cleaned['Keywords_Present'] = df_cleaned['Tokens'].apply(check_keywords)\n","df_cleaned['Keywords_Present2'] = df_cleaned['Stemmed'].apply(check_keywords)\n","df_cleaned['Keywords_Present3'] = df_cleaned['Lemmatized'].apply(check_keywords)\n","\n","def is_empty(lst):\n","    if len(lst) == 0:\n","        return 0\n","    else:\n","        return 1\n","\n","df_cleaned['is_non_empty'] = df_cleaned['Keywords_Present'].apply(is_empty)\n","df_cleaned['is_non_empty2'] = df_cleaned['Keywords_Present2'].apply(is_empty)\n","df_cleaned['is_non_empty3'] = df_cleaned['Keywords_Present3'].apply(is_empty)\n","\n","df_cleaned['Cancer'] = df_cleaned['is_non_empty'] + df_cleaned['is_non_empty2'] + df_cleaned['is_non_empty3']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["med = []\n","\n","for cancer_type in cancer_list['Active ingredient'].dropna():\n","    med.append(cancer_type)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cleaned['testing'] = df_cleaned['Keywords_Present'] +df_cleaned['Keywords_Present2'] +df_cleaned['Keywords_Present3']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def checkuniq(lst):\n","    splits = lst.split(\" \")\n","    uniques = ['cancer','specimen','chemo','tumor']\n","\n","    if len(splits) >= 1:\n","        for i in splits:\n","            if i in uniques:\n","                split2 = [x for x in splits if x not in uniques]\n","                if len(split2) >= 1:\n","                    #print(\"one\")\n","                    return splits[0]\n","                else:\n","                    #print(\"two\")\n","                    return split2[1]\n","\n","            else:\n","                #print(\"three\")\n","                return splits[0]\n","    elif len(splits) == 1:\n","        #print(\"four\")\n","        return \"cancer\"\n","df_cleaned['MainCancer'] = df_cleaned['testing'].apply(checkuniq)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S/N</th>\n","      <th>Gender</th>\n","      <th>DOB</th>\n","      <th>Age</th>\n","      <th>Consultant</th>\n","      <th>Provider</th>\n","      <th>Type</th>\n","      <th>Ward Type</th>\n","      <th>Invoice No.</th>\n","      <th>Heading</th>\n","      <th>...</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>Tokens</th>\n","      <th>Stemmed</th>\n","      <th>Lemmatized</th>\n","      <th>is_non_empty</th>\n","      <th>is_non_empty2</th>\n","      <th>is_non_empty3</th>\n","      <th>testing</th>\n","      <th>MainCancer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>A&amp;E/SOC SERVICES</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>30</td>\n","      <td>[raffles, hosptial, a, services, 512000, soc, ...</td>\n","      <td>[raffl, hosptial, a, servic, 512000, soc, serv...</td>\n","      <td>[raffle, hosptial, a, service, 512000, soc, se...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>ACCOMMODATION</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>30</td>\n","      <td>[raffles, hosptial, accommodation, a080307, si...</td>\n","      <td>[raffl, hosptial, accommod, a080307, singl, ro...</td>\n","      <td>[raffle, hosptial, accommodation, a080307, sin...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>ACCOMMODATION</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>[raffles, hosptial, accommodation, a080307, si...</td>\n","      <td>[raffl, hosptial, accommod, a080307, singl, ro...</td>\n","      <td>[raffle, hosptial, accommodation, a080307, sin...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>CONSULTATION</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>[raffles, hosptial, consultation, a070078, war...</td>\n","      <td>[raffl, hosptial, consult, a070078, ward, rmo,...</td>\n","      <td>[raffle, hosptial, consultation, a070078, ward...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>CONSULTATION</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>14</td>\n","      <td>[raffles, hosptial, consultation, a010031, sub...</td>\n","      <td>[raffl, hosptial, consult, a010031, sub, consu...</td>\n","      <td>[raffle, hosptial, consultation, a010031, sub,...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>219590</th>\n","      <td>1815</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>20</td>\n","      <td>[ttsh, services, ms0800, facilitation, adminis...</td>\n","      <td>[ttsh, servic, ms0800, facilit, administr, met...</td>\n","      <td>[ttsh, service, ms0800, facilitation, administ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>cholangiocarcinoma metastasis cholangiocarcino...</td>\n","      <td>cholangiocarcinoma</td>\n","    </tr>\n","    <tr>\n","      <th>219591</th>\n","      <td>1816</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>HD Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>25</td>\n","      <td>[ttsh, services, ms0800, facilitation, adminis...</td>\n","      <td>[ttsh, servic, ms0800, facilit, administr, met...</td>\n","      <td>[ttsh, service, ms0800, facilitation, administ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>cholangiocarcinoma metastasis cholangiocarcino...</td>\n","      <td>cholangiocarcinoma</td>\n","    </tr>\n","    <tr>\n","      <th>219592</th>\n","      <td>1817</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>ICU Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>26</td>\n","      <td>[ttsh, services, ms0800, facilitation, adminis...</td>\n","      <td>[ttsh, servic, ms0800, facilit, administr, met...</td>\n","      <td>[ttsh, service, ms0800, facilitation, administ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>cholangiocarcinoma metastasis cholangiocarcino...</td>\n","      <td>cholangiocarcinoma</td>\n","    </tr>\n","    <tr>\n","      <th>219593</th>\n","      <td>1818</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>ICU Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>[ttsh, services, ms0800, facilitation, adminis...</td>\n","      <td>[ttsh, servic, ms0800, facilit, administr, met...</td>\n","      <td>[ttsh, service, ms0800, facilitation, administ...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>cholangiocarcinoma metastasis cholangiocarcino...</td>\n","      <td>cholangiocarcinoma</td>\n","    </tr>\n","    <tr>\n","      <th>219594</th>\n","      <td>1819</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>ICU Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>[ttsh, services, ws058, tissue, paper, per, bo...</td>\n","      <td>[ttsh, servic, ws058, tissu, paper, per, box, ...</td>\n","      <td>[ttsh, service, ws058, tissue, paper, per, box...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>cholangiocarcinoma metastasis cholangiocarcino...</td>\n","      <td>cholangiocarcinoma</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>219033 rows × 43 columns</p>\n","</div>"],"text/plain":["         S/N Gender   DOB  Age Consultant          Provider       Type  \\\n","0          1      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","1          2      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","2          3      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","3          4      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","4          5      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","...      ...    ...   ...  ...        ...               ...        ...   \n","219590  1815      F  1949   75        NaN              TTSH  Inpatient   \n","219591  1816      F  1949   75        NaN              TTSH  Inpatient   \n","219592  1817      F  1949   75        NaN              TTSH  Inpatient   \n","219593  1818      F  1949   75        NaN              TTSH  Inpatient   \n","219594  1819      F  1949   75        NaN              TTSH  Inpatient   \n","\n","           Ward Type Invoice No.                  Heading  ... Month Day  \\\n","0             Normal   2020803751       A&E/SOC SERVICES   ...     3  30   \n","1             Normal   2020803751          ACCOMMODATION   ...     3  30   \n","2             Normal   2020803751          ACCOMMODATION   ...     4  17   \n","3             Normal   2020803751           CONSULTATION   ...     4   3   \n","4             Normal   2020803751           CONSULTATION   ...     4  14   \n","...              ...          ...                     ...  ...   ...  ..   \n","219590      Class A1  1219533524G  NON-TREATMENT SERVICES  ...     9  20   \n","219591   HD Class A1  1219533524G  NON-TREATMENT SERVICES  ...     9  25   \n","219592  ICU Class A1  1219533524G  NON-TREATMENT SERVICES  ...     9  26   \n","219593  ICU Class A1  1219533524G  NON-TREATMENT SERVICES  ...     9  27   \n","219594  ICU Class A1  1219533524G  NON-TREATMENT SERVICES  ...     9  27   \n","\n","                                                   Tokens  \\\n","0       [raffles, hosptial, a, services, 512000, soc, ...   \n","1       [raffles, hosptial, accommodation, a080307, si...   \n","2       [raffles, hosptial, accommodation, a080307, si...   \n","3       [raffles, hosptial, consultation, a070078, war...   \n","4       [raffles, hosptial, consultation, a010031, sub...   \n","...                                                   ...   \n","219590  [ttsh, services, ms0800, facilitation, adminis...   \n","219591  [ttsh, services, ms0800, facilitation, adminis...   \n","219592  [ttsh, services, ms0800, facilitation, adminis...   \n","219593  [ttsh, services, ms0800, facilitation, adminis...   \n","219594  [ttsh, services, ws058, tissue, paper, per, bo...   \n","\n","                                                  Stemmed  \\\n","0       [raffl, hosptial, a, servic, 512000, soc, serv...   \n","1       [raffl, hosptial, accommod, a080307, singl, ro...   \n","2       [raffl, hosptial, accommod, a080307, singl, ro...   \n","3       [raffl, hosptial, consult, a070078, ward, rmo,...   \n","4       [raffl, hosptial, consult, a010031, sub, consu...   \n","...                                                   ...   \n","219590  [ttsh, servic, ms0800, facilit, administr, met...   \n","219591  [ttsh, servic, ms0800, facilit, administr, met...   \n","219592  [ttsh, servic, ms0800, facilit, administr, met...   \n","219593  [ttsh, servic, ms0800, facilit, administr, met...   \n","219594  [ttsh, servic, ws058, tissu, paper, per, box, ...   \n","\n","                                               Lemmatized is_non_empty  \\\n","0       [raffle, hosptial, a, service, 512000, soc, se...            0   \n","1       [raffle, hosptial, accommodation, a080307, sin...            0   \n","2       [raffle, hosptial, accommodation, a080307, sin...            0   \n","3       [raffle, hosptial, consultation, a070078, ward...            0   \n","4       [raffle, hosptial, consultation, a010031, sub,...            0   \n","...                                                   ...          ...   \n","219590  [ttsh, service, ms0800, facilitation, administ...            1   \n","219591  [ttsh, service, ms0800, facilitation, administ...            1   \n","219592  [ttsh, service, ms0800, facilitation, administ...            1   \n","219593  [ttsh, service, ms0800, facilitation, administ...            1   \n","219594  [ttsh, service, ws058, tissue, paper, per, box...            1   \n","\n","       is_non_empty2  is_non_empty3  \\\n","0                  0              0   \n","1                  0              0   \n","2                  0              0   \n","3                  0              0   \n","4                  0              0   \n","...              ...            ...   \n","219590             1              1   \n","219591             1              1   \n","219592             1              1   \n","219593             1              1   \n","219594             1              1   \n","\n","                                                  testing          MainCancer  \n","0                                                                              \n","1                                                                              \n","2                                                                              \n","3                                                                              \n","4                                                                              \n","...                                                   ...                 ...  \n","219590  cholangiocarcinoma metastasis cholangiocarcino...  cholangiocarcinoma  \n","219591  cholangiocarcinoma metastasis cholangiocarcino...  cholangiocarcinoma  \n","219592  cholangiocarcinoma metastasis cholangiocarcino...  cholangiocarcinoma  \n","219593  cholangiocarcinoma metastasis cholangiocarcino...  cholangiocarcinoma  \n","219594  cholangiocarcinoma metastasis cholangiocarcino...  cholangiocarcinoma  \n","\n","[219033 rows x 43 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["df_cleaned"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#hard code exclsuion list\n","df_cleaned2 = df_cleaned\n","\n","def removedata(texts):\n","    exc = ['others']\n","    if texts in exc:\n","        return \" \"\n","    \n","#df_cleaned['MainCancer'] = df_cleaned['MainCancer'].apply(removedata)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#df_cleaned.to_excel('OCR_excel.xlsx', index=False)\n","def check_keywords2(tokens):\n","    plist = [\"and\",\"511001\", \"4001000036\",\"4001000038\",\"4001000037\",'the','novena','parkway']\n","    counter = 0 \n","    for token in tokens:\n","        if token == \"cancer\":\n","            counters = counter - 1\n","            if tokens[counters] not in plist:\n","                return tokens[counters]\n","        counter += 1\n","\n","df_cleaned['cancer2'] = df_cleaned['Tokens'].apply(check_keywords2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def combinecol (cola, colb):\n","    if cola == \"cancer\" and colb != \" \":\n","        return colb\n","    elif cola == \" \":\n","        return colb\n","    else:\n","        return cola"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cleaned['CancerCat'] = df_cleaned.apply(lambda row: combinecol(row['MainCancer'], row['cancer2']), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S/N</th>\n","      <th>Gender</th>\n","      <th>DOB</th>\n","      <th>Age</th>\n","      <th>Consultant</th>\n","      <th>Provider</th>\n","      <th>Type</th>\n","      <th>Ward Type</th>\n","      <th>Invoice No.</th>\n","      <th>Heading</th>\n","      <th>...</th>\n","      <th>Cancer</th>\n","      <th>Year</th>\n","      <th>tempmonth</th>\n","      <th>tempday</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>MainCancer</th>\n","      <th>CancerCat</th>\n","      <th>Patient</th>\n","      <th>CancerPatient</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>A&amp;E/SOC SERVICES</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>2020</td>\n","      <td>3</td>\n","      <td>30</td>\n","      <td>3</td>\n","      <td>30</td>\n","      <td></td>\n","      <td></td>\n","      <td>Raffles Hosptial-1211</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>ACCOMMODATION</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>2020</td>\n","      <td>3</td>\n","      <td>30</td>\n","      <td>3</td>\n","      <td>30</td>\n","      <td></td>\n","      <td></td>\n","      <td>Raffles Hosptial-1211</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>ACCOMMODATION</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>2020</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td></td>\n","      <td></td>\n","      <td>Raffles Hosptial-1211</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>CONSULTATION</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>2020</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td></td>\n","      <td></td>\n","      <td>Raffles Hosptial-1211</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>F</td>\n","      <td>1972</td>\n","      <td>52</td>\n","      <td>NaN</td>\n","      <td>Raffles Hosptial</td>\n","      <td>Inpatient</td>\n","      <td>Normal</td>\n","      <td>2020803751</td>\n","      <td>CONSULTATION</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>2020</td>\n","      <td>4</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>14</td>\n","      <td></td>\n","      <td></td>\n","      <td>Raffles Hosptial-1211</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>219590</th>\n","      <td>1815</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2019</td>\n","      <td>9</td>\n","      <td>20</td>\n","      <td>9</td>\n","      <td>20</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>TTSH-1148</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>219591</th>\n","      <td>1816</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>HD Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2019</td>\n","      <td>9</td>\n","      <td>25</td>\n","      <td>9</td>\n","      <td>25</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>TTSH-1148</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>219592</th>\n","      <td>1817</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>ICU Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2019</td>\n","      <td>9</td>\n","      <td>26</td>\n","      <td>9</td>\n","      <td>26</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>TTSH-1148</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>219593</th>\n","      <td>1818</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>ICU Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2019</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>TTSH-1148</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>219594</th>\n","      <td>1819</td>\n","      <td>F</td>\n","      <td>1949</td>\n","      <td>75</td>\n","      <td>NaN</td>\n","      <td>TTSH</td>\n","      <td>Inpatient</td>\n","      <td>ICU Class A1</td>\n","      <td>1219533524G</td>\n","      <td>NON-TREATMENT SERVICES</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2019</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>9</td>\n","      <td>27</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>cholangiocarcinoma</td>\n","      <td>TTSH-1148</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>219033 rows × 35 columns</p>\n","</div>"],"text/plain":["         S/N Gender   DOB  Age Consultant          Provider       Type  \\\n","0          1      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","1          2      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","2          3      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","3          4      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","4          5      F  1972   52        NaN  Raffles Hosptial  Inpatient   \n","...      ...    ...   ...  ...        ...               ...        ...   \n","219590  1815      F  1949   75        NaN              TTSH  Inpatient   \n","219591  1816      F  1949   75        NaN              TTSH  Inpatient   \n","219592  1817      F  1949   75        NaN              TTSH  Inpatient   \n","219593  1818      F  1949   75        NaN              TTSH  Inpatient   \n","219594  1819      F  1949   75        NaN              TTSH  Inpatient   \n","\n","           Ward Type Invoice No.                  Heading  ... Cancer  Year  \\\n","0             Normal   2020803751       A&E/SOC SERVICES   ...      0  2020   \n","1             Normal   2020803751          ACCOMMODATION   ...      0  2020   \n","2             Normal   2020803751          ACCOMMODATION   ...      0  2020   \n","3             Normal   2020803751           CONSULTATION   ...      0  2020   \n","4             Normal   2020803751           CONSULTATION   ...      0  2020   \n","...              ...          ...                     ...  ...    ...   ...   \n","219590      Class A1  1219533524G  NON-TREATMENT SERVICES  ...      3  2019   \n","219591   HD Class A1  1219533524G  NON-TREATMENT SERVICES  ...      3  2019   \n","219592  ICU Class A1  1219533524G  NON-TREATMENT SERVICES  ...      3  2019   \n","219593  ICU Class A1  1219533524G  NON-TREATMENT SERVICES  ...      3  2019   \n","219594  ICU Class A1  1219533524G  NON-TREATMENT SERVICES  ...      3  2019   \n","\n","       tempmonth tempday Month Day          MainCancer           CancerCat  \\\n","0              3      30     3  30                                           \n","1              3      30     3  30                                           \n","2              4      17     4  17                                           \n","3              4       3     4   3                                           \n","4              4      14     4  14                                           \n","...          ...     ...   ...  ..                 ...                 ...   \n","219590         9      20     9  20  cholangiocarcinoma  cholangiocarcinoma   \n","219591         9      25     9  25  cholangiocarcinoma  cholangiocarcinoma   \n","219592         9      26     9  26  cholangiocarcinoma  cholangiocarcinoma   \n","219593         9      27     9  27  cholangiocarcinoma  cholangiocarcinoma   \n","219594         9      27     9  27  cholangiocarcinoma  cholangiocarcinoma   \n","\n","                      Patient CancerPatient  \n","0       Raffles Hosptial-1211             1  \n","1       Raffles Hosptial-1211             1  \n","2       Raffles Hosptial-1211             1  \n","3       Raffles Hosptial-1211             1  \n","4       Raffles Hosptial-1211             1  \n","...                       ...           ...  \n","219590              TTSH-1148             1  \n","219591              TTSH-1148             1  \n","219592              TTSH-1148             1  \n","219593              TTSH-1148             1  \n","219594              TTSH-1148             1  \n","\n","[219033 rows x 35 columns]"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["df_cleaned['CancerPatient'] = df_cleaned.groupby('Patient')['CancerCat'].transform(lambda x: 1 if x.notna().any() else 0)\n","df_cleaned"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","columns_to_drop = ['is_non_empty', 'is_non_empty2','is_non_empty3','Tokens','Stemmed','Lemmatized','testing',\n","                   'testing','cancer2',\"NLP\",\"Keywords_Present\",'Keywords_Present2','Keywords_Present3']\n","\n","df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Combined data has been written to Output/OCR_excel_LY.xlsx\n"]}],"source":["\n","\n","def normalise(norm):\n","    if norm == \"leukemia\":\n","        return \"leukaemia\"\n","\n","#df_cleaned['Combined'] = df_cleaned['Combined'].apply(normalise)\n","\n","# Specify the path for the new Excel file\n","output_excel_path = 'Output/OCR_excel_LY.xlsx'\n","\n","# Write the combined dataframe to a new Excel file\n","df_cleaned.to_excel(output_excel_path, index=False)\n","\n","# Display a message indicating the success\n","print(f\"Combined data has been written to {output_excel_path}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_cleaned.head()"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":2}
